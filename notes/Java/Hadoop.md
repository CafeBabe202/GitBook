# ğŸ˜„ Hadoop

### Hadoopæ¦‚å¿µ

#### Hadoopæ˜¯ä»€ä¹ˆ

![image-20230102150408850](Hadoop.assets/image-20230102150408850-167301126209327.png)

#### Hadoopå‘å±•å²

![image-20230102150848014](Hadoop.assets/image-20230102150848014-167301128078128.png)

![image-20230102150848014-16730108736602](<Hadoop.assets/image-20230102150848014-16730108736602-167301129616729 (1).png>)

![image-20230102151224000](Hadoop.assets/image-20230102151224000-167301132773830.png)

![image-20230102151224000-16730108777793](Hadoop.assets/image-20230102151224000-16730108777793.png)

#### Hadoopçš„ä¸‰å¤§å‘è¡Œç‰ˆ

![image-20230102151457044](Hadoop.assets/image-20230102151457044-167301134141731.png)

#### Hadoopçš„ä¼˜åŠ¿

![image-20230102153334381](Hadoop.assets/image-20230102153334381-167301151381634.png)

![image-20230102153304044-16730108911166](Hadoop.assets/image-20230102153304044-16730108911166.png)

#### Hadoopçš„ç»„æˆï¼ˆé¢è¯•é‡ç‚¹ï¼‰

![image-20230102153712755](Hadoop.assets/image-20230102153712755-167301155776135.png)

**HDFSæ¦‚è¿°**

![image-20230102154312210](Hadoop.assets/image-20230102154312210-167301159820136.png)

![image-20230102154453130](Hadoop.assets/image-20230102154453130-167301161483437.png)

**YARNèµ„æºè°ƒåº¦**

![image-20230102155128090](Hadoop.assets/image-20230102155128090-167301163511638.png)

ä¸€ä¸ªcontaineréœ€è¦1-8Gå†…å­˜ï¼Œè‡³å°‘1ä¸ªCPUã€‚

![image-20230102155415464](Hadoop.assets/image-20230102155415464-167301166772739.png)

![image-20230102155759126](Hadoop.assets/image-20230102155759126-167301168553440.png)

#### å¤§æ•°æ®æŠ€æœ¯ç”Ÿæ€ä½“ç³»

![image-20230102160533390-167301096245013](Hadoop.assets/image-20230102160533390-167301096245013.png)

#### æ¨èç³»ç»Ÿæ¡ˆä¾‹

### ç¯å¢ƒæ­å»º

#### æ¨¡æ¿è™šæ‹Ÿæœºå‡†å¤‡

å®‰è£…ä¸€ä¸ªè™šæ‹Ÿæœºï¼Œæˆ‘æ˜¯åœ¨ PVE ä¸­å®‰è£…çš„ openSUSE è™šæ‹Ÿæœºã€‚

é…ç½®

* CPU:ï¼š2
* å†…å­˜ï¼š4G
* ç£ç›˜ï¼š64G

å†…å­˜å’Œç£ç›˜ä¸è¦å¤ªå°ï¼Œå› ä¸ºæ¯ä¸€ä¸ª yarn ä»»åŠ¡é»˜è®¤éœ€è¦ 1G çš„å†…å­˜ï¼Œå¤§ä¸€ç‚¹æ–¹ä¾¿ä½¿ç”¨ã€‚

åˆ›å»ºä¸€ä¸ªæ™®é€šç”¨æˆ·ï¼Œä¸å»ºè®®ä½¿ç”¨ root ç”¨æˆ·å¯¹ Hadoop é›†ç¾¤è¿›è¡Œæ“ä½œï¼Œæ‰€ä»¥å®‰è£…ç¯å¢ƒå°±ä½¿ç”¨é root ç”¨æˆ·ï¼Œé¿å…å‡ºç°æƒé™é—®é¢˜ã€‚

**å®‰è£…JDKã€Hadoop**

å®‰è£… JDK-11 å’Œ Hadoop-3.1.3ï¼Œå¹¶é…ç½®ç¯å¢ƒå˜é‡ã€‚

```shell
> cat /etc/profile.d/my_env.sh 
export JAVA_HOME=/home/zh/bin/jdk-11
export Hadoop_HOME=/home/zh/bin/Hadoop-3.1.3
export PATH=$PATH:$JAVA_HOME/bin:$Hadoop_HOME/bin:$Hadoop_HOME/sbin
```

Hadoop ä¹Ÿè¦é…ç½®å¯¹åº”çš„ home ç›®å½•ï¼Œå¹¶ä¸”ï¼Œå»ºè®®åŒæ—¶é…ç½® sbin ç›®å½•ï¼Œæ–¹ä¾¿ä½¿ç”¨ã€‚

ç¯å¢ƒå˜é‡çš„é…ç½®å¹¶ä¸æ˜¯ç›´æ¥åœ¨ `/etc/profile` æ–‡ä»¶ï¼ŒSUSE å¯¹ `/etc/profile` çš„å£°æ˜å¦‚ä¸‹ï¼š

```shell
# PLEASE DO NOT CHANGE /etc/profile. There are chances that your changes
# will be lost during system upgrades. Instead use /etc/profile.local for
# your local settings, favourite global aliases, VISUAL and EDITOR
# variables, etc ...
```

æ„æ€å°±æ˜¯è¯´å¦‚æœç³»ç»Ÿå‡çº§å°†ä¼šé‡æ–°é…ç½®è¯¥æ–‡ä»¶ï¼Œä¼šå¯¼è‡´è‡ªå®šä¹‰é…ç½®å¤±æ•ˆï¼Œè¯¥æ–‡ä»¶ä¼šè‡ªåŠ¨æ·»åŠ  `/etc/profile.d` ä¸‹çš„æ–‡ä»¶ï¼Œæ‰€ä»¥åº”è¯¥åœ¨ `/etc/profile.d` ä¸‹åˆ›å»ºæ–°çš„æ–‡ä»¶æ¥è‡ªå®šä¹‰ç¯å¢ƒå˜é‡ã€‚

**å…¶ä»–é…ç½®**

ç½‘ç»œ ip åœ°å€ä¸ºï¼š192.168.1.102ï¼Œhostname ä¸ºï¼šHadoop102ï¼Œ**å¹¶å…³é—­é˜²ç«å¢™**ã€‚

é…ç½® hosts æ–‡ä»¶ï¼š

| hostname |   Hadoop102   |   Hadoop103   |   Hadoop104   |
| :------: | :-----------: | :-----------: | :-----------: |
|    ip    | 192.168.1.102 | 192.168.1.103 | 192.168.1.104 |

é…ç½® ssh çš„å…å¯†ç™»é™†ï¼Œé¦–å…ˆç”Ÿæˆå¯†é’¥å’Œå…¬é’¥ã€‚

```shell
> ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/home/zh/.ssh/id_rsa): 
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in /home/zh/.ssh/id_rsa
Your public key has been saved in /home/zh/.ssh/id_rsa.pub
The key fingerprint is:
SHA256:zfwWw2j9jOv10NlzFDrcsD5ezDKeFT4LBjPFdnYvfxA zh@Hadoop102
The key's randomart image is:
+---[RSA 3072]----+
|                 |
|            .    |
|             =E+.|
|         + ++ B.+|
|        S *+==ooo|
|         . .=*=*+|
|            +B=X*|
|           .+oOo*|
|           .o+ ..|
+----[SHA256]-----+
```

ç”Ÿæˆå¯†é’¥å’Œå…¬é’¥ä¹‹åå°†å…¬é’¥ä¸Šä¼ åˆ°éœ€è¦å…å¯†ç™»é™†çš„æœåŠ¡å™¨ä¸Šï¼Œå› ä¸ºè¿™æ˜¯æ¨¡æ¿è™šæ‹Ÿæœºï¼Œæ‰€ä»¥ä¸Šä¼ ç»™è‡ªå·±å°±å¯ä»¥ï¼Œå…‹éš†åå°±å¯ä»¥ä½¿ç”¨äº†ã€‚

```shell
> ssh-copy-id 192.168.1.102
/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/home/zh/.ssh/id_rsa.pub"
The authenticity of host '192.168.1.102 (192.168.1.102)' can't be established.
ECDSA key fingerprint is SHA256:rfMm+vaeZgiQUFcODiLhKgO3Gs31sZHyordqn8+n6e0.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
Password: 

Number of key(s) added: 1

Now try logging into the machine, with:   "ssh '192.168.1.102'"
and check to make sure that only the key(s) you wanted were added.
```

é€šè¿‡ä¸Šè¿°çš„å‘½ä»¤ä¼šè‡ªåŠ¨å°†åˆšåˆšç”Ÿæˆçš„å…¬é’¥æ‹·è´åˆ°ç›®æ ‡æœåŠ¡å™¨çš„åŒç”¨æˆ·åçš„ .ssh æ–‡ä»¶å¤¹ä¸‹ï¼Œè¿™æ ·ä»¥åå°±å¯ä»¥é€šè¿‡ **ssh hostname** çš„æ–¹å¼ç™»é™†ç›®æ ‡æœåŠ¡å™¨çš„åŒç”¨æˆ·åè´¦æˆ·äº†ã€‚

åœ¨é›†ç¾¤ä¸­è¿›è¡Œæ–‡ä»¶çš„ä¼ è¾“æœ‰è¿ä¸ªå¸¸ç”¨çš„å‘½ä»¤ï¼Œåˆ†åˆ«æ˜¯ scp å’Œ rsyncï¼Œç”¨æ³•å¦‚ä¸‹ï¼š

```shell
# æ–‡ä»¶æ‹·è´å‘½ä»¤ï¼Œä»æœ¬åœ°åˆ°è¿œç¨‹æœåŠ¡å™¨ï¼Œå¯ä»¥å°†è¿ä¸ªéƒ¨åˆ†è°ƒè¿‡æ¥ï¼Œä»è¿œç¨‹åˆ°æœ¬åœ°
scp æºåœ°å€ ç”¨æˆ·å@hostname:ç›®æ ‡åœ°å€

# æ–‡ä»¶åŒæ­¥å·¥å…·ï¼Œå¯ä»¥åªå¤åˆ¶æœ€æ–°æ›´æ”¹çš„æ–‡ä»¶ï¼ŒåŒæ ·å¯ä»¥è°ƒæ¢ä¸¤ä¸ªåœ°å€
rsync æºåœ°å€ ç”¨æˆ·å@hostname:ç›®æ ‡åœ°å€
```

å› ä¸ºé›†ç¾¤éœ€è¦ç»å¸¸è¿›è¡Œé…ç½®çš„åˆ†å‘ï¼Œå¹¶ä¸éœ€è¦å¯¹æ‰€æœ‰æ–‡ä»¶è¿›è¡Œå…¨éƒ¨å¤åˆ¶ï¼Œåªè¦æ›´æ–°å˜åŒ–çš„æ–‡ä»¶å°±å¯ä»¥ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹çš„è„šæœ¬æ–¹ä¾¿ä½¿ç”¨ã€‚

```shell
#!/bin/bash
if [ $# -lt 1 ];then
        echo "args errors!"
        exit
fi

for Hadoop in Hadoop102 Hadoop103 Hadoop104;do
        for f in $@;do
                if [ -d $f ];then
                        ssh $Hadoop mkdir -p $(pwd)/$f
                        rsync -av $f $Hadoop:$(pwd)/$f
                else
                        echo $f not exists
                fi
        done
done
```

æ„Ÿè§‰ä¸Šè¾¹çš„è„šæœ¬å¹¶ä¸å®Œç¾ï¼Œä½†æ˜¯æˆ‘ä¹Ÿä¸ä¼šæ”¹ ^ \_ ^ ã€‚

**æµ‹è¯•**

é¦–å…ˆæ£€æŸ¥ java å’Œ Hadoop ç¯å¢ƒå˜é‡æ˜¯å¦æœ‰æ•ˆï¼Œç„¶åæ£€æŸ¥ç½‘ç»œé…ç½®å¹¶æµ‹è¯•ç½‘ç»œæ˜¯å¦è¿åŒã€‚

æœ€åé€šè¿‡ä»¥ä¸‹æ¼”ç¤ºæ‰§è¡Œ Hadoop çš„ workdCount ç¨‹åºæ£€æŸ¥ Hadoop æ˜¯å¦èƒ½å¤Ÿå·¥ä½œã€‚é¦–å…ˆåˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ç”¨æ¥å­˜æ”¾è¾“å…¥çš„æ–‡ä»¶ï¼Œå¹¶ä¸”åœ¨å…¶ä¸­æ–°å»ºä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶è¾“å…¥äº›å•è¯ï¼Œä½¿ç”¨ç©ºæ ¼åˆ†å¼€ã€‚

```shell
> mkdir wcinput
> vim wcinput/word.txt
zh dahai
cls zh
zh ada
dahai zh ada cls
```

æ‰§è¡Œ Hadoop çš„ wordcount ç¨‹åºæµ‹è¯• Hadoop æ˜¯å¦èƒ½å¤Ÿæ­£å¸¸å·¥ä½œã€‚

```shell
> Hadoop jar bin/Hadoop-3.1.3/share/Hadoop/mapreduce/Hadoop-mapreduce-examples-3.1.3.jar wordcount wcinput wcoutput
2023-01-04 20:53:36,863 INFO impl.MetricsConfig: loaded properties from Hadoop-metrics2.properties
2023-01-04 20:53:36,918 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2023-01-04 20:53:36,918 INFO impl.MetricsSystemImpl: JobTracker metrics system started
2023-01-04 20:53:36,997 INFO input.FileInputFormat: Total input files to process : 1
......
2023-01-04 20:53:38,205 INFO mapreduce.Job:  map 100% reduce 100%
2023-01-04 20:53:38,206 INFO mapreduce.Job: Job job_local689621915_0001 completed successfully
2023-01-04 20:53:38,213 INFO mapreduce.Job: Counters: 30
......
```

å¦‚æœä¸Šè¿°æ‰§è¡Œæ²¡æœ‰æŠ¥é”™ï¼Œè¯´æ˜ç¨‹åºæ‰§è¡ŒæˆåŠŸï¼Œè¾“å‡ºè·¯å¾„ä¸‹ç”Ÿæˆçš„ \_SUCCESS æ²¡æœ‰ä»»ä½•å†…å®¹ï¼Œè¡¨ç¤ºç¨‹åºæˆåŠŸï¼Œpart-r-00000 æ–‡ä»¶ç”¨æ¥å­˜æ”¾è¾“å‡ºç»“æœã€‚

```shell
> ls
bin  wcinput  wcoutput

> cd wcoutput
part-r-00000  _SUCCESS

> cat part-r-00000 
ada     2
cls     2
dahai   2
zh      4
```

å¦‚æœä¸Šè¿°æµ‹è¯•å…¨éƒ¨é€šè¿‡åˆ™è¯´æ˜ç›®å‰é…ç½®æ²¡æœ‰é—®é¢˜ï¼Œå¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œã€‚å¦‚æœé‡æ–°æ‰§è¡Œ wordcount ç¨‹åºè¯·åˆ é™¤è¾“å‡ºç›®å½•ï¼Œå¦‚æœä¸åˆ é™¤ç¬¬äºŒæ¬¡æ‰§è¡Œå°†ä¼šæŠ¥è¾“å‡ºè·¯å¾„å·²å­˜åœ¨çš„é”™è¯¯ã€‚

#### é›†ç¾¤é…ç½®

**å…‹éš†è™šæ‹Ÿæœº**

å°†ä¸Šè¾¹é…ç½®å¥½çš„æ¨¡æ¿è™šæ‹Ÿæœºå…‹éš†ä¸¤ä»½ï¼Œæœ€åä¸€å…±å¾—åˆ°ä¸‰ä¸ªè™šæ‹Ÿæœºï¼Œåˆ†åˆ«ä¿®æ”¹ hostname å’Œ ip åœ°å€ã€‚

ä¿®æ”¹å®Œæˆä¹‹åæµ‹è¯•æ˜¯å¦å¯ä»¥ç›¸äº’å…å¯†ç™»é™†ï¼Œæ˜¯å¦å¯ä»¥è¿›è¡Œé…ç½®çš„åˆ†å‘ã€‚

**Hadoop è¿è¡Œæ¨¡å¼**

**æœ¬åœ°æ¨¡å¼**

æ•°æ®å­˜å‚¨åœ¨Linuxæœ¬åœ°ã€‚åªæ˜¯åœ¨æµ‹è¯•æ—¶**å¶å°”**ç”¨ä¸€ä¸‹ã€‚

**ä¼ªåˆ†å¸ƒå¼**

è™½ç„¶åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œä½†æ˜¯æ•°æ®æ˜¯å­˜å‚¨åœ¨HDFSçš„ã€‚æ²¡é’±æˆ–è€…æ•°æ®é‡ä¸å¤§çš„å…¬å¸ã€‚

**å®Œå…¨åˆ†å¸ƒå¼é›†ç¾¤ï¼ˆå¼€å‘é‡ç‚¹ï¼‰**

æœ‰å¤šå°æœåŠ¡å™¨åŒæ—¶è¿›è¡ŒæœåŠ¡ã€‚åœ¨ä¼ä¸šä¸­å¤§é‡ä½¿ç”¨ã€‚

**èŠ‚ç‚¹é…ç½®**

**Hadoop å¸¸è§å‘½ä»¤**

Hadoop çš„å¸¸ç”¨å‘½ä»¤å­˜åœ¨ä¸¤ä¸ªæ–‡ä»¶å¤¹ä¸‹ï¼Œå¸¸è§çš„å‘½ä»¤åŠè¯´æ˜å¦‚ä¸‹:

* Hadoopï¼šç”¨äºç®¡ç†HDFSæ–‡ä»¶ç³»ç»Ÿçš„å‘½ä»¤ï¼ŒåŒ…æ‹¬åˆ›å»ºç›®å½•ã€ä¸Šä¼ ã€ä¸‹è½½ã€åˆ é™¤ç­‰ã€‚
* hdfsï¼šç”¨äºç®¡ç†HDFSæœåŠ¡çš„å‘½ä»¤ï¼ŒåŒ…æ‹¬å¯åŠ¨ã€åœæ­¢ã€æŸ¥çœ‹çŠ¶æ€ç­‰ã€‚
* yarnï¼šç”¨äºç®¡ç†YARNèµ„æºè°ƒåº¦çš„å‘½ä»¤ï¼ŒåŒ…æ‹¬æäº¤ã€æŸ¥çœ‹ä½œä¸šçŠ¶æ€ç­‰ã€‚
* mapredï¼šç”¨äºç®¡ç†MapReduceä½œä¸šçš„å‘½ä»¤ï¼ŒåŒ…æ‹¬æäº¤ã€æŸ¥çœ‹ä½œä¸šçŠ¶æ€ç­‰ã€‚
* start/stop-dfs/yarnï¼šç”¨æ¥å¯åŠ¨/åœæ­¢ dfs/yarn é›†ç¾¤ã€‚
* start/stop-dfs/yarn-demonsï¼šç”¨æ¥å•èŠ‚ç‚¹å¯åŠ¨/åœæ­¢ dfs/yarnã€‚
* mr-jobhistory-daemonï¼šç”¨æ¥å¯åŠ¨å†å²ä»»åŠ¡æœåŠ¡å™¨ã€‚

**é›†ç¾¤è§„åˆ’**

Hadoop æ˜¯é›†ç¾¤è¿è¡Œçš„ç³»ç»Ÿï¼Œå¹¶ä¸”åˆ†ä¸ºè®¸å¤šéƒ¨åˆ†ï¼Œé€šè¿‡é…ç½®ä½¿å¾—ä¸åŒçš„èŠ‚ç‚¹è¿è¡Œä¸åŒçš„æœåŠ¡ï¼Œä½†æ˜¯è®¾è®¡é›†ç¾¤æ—¶æœ€å¥½éµä»ä»¥ä¸‹çš„è§„èŒƒï¼š

* NameNodeã€ResourceManager å’Œ SecondNameNode ä¸è¦å†åŒä¸€å°æœåŠ¡å™¨ï¼Œå› ä¸ºè¿™äº›ç®¡ç†æœåŠ¡éƒ½éœ€è¦å ç”¨èµ„æºï¼Œæ‰€ä»¥å°½é‡ä¸è¦åœ¨åŒä¸€å°æœåŠ¡å™¨åŒæ—¶éƒ¨ç½²ï¼Œé˜²æ­¢å•å°å‹åŠ›è¿‡å¤§ã€‚
* NameNode å’Œ SecondNameNode ä¸è¦å†åŒä¸€å°æœåŠ¡å™¨ï¼Œé¦–å…ˆæ˜¯å› ä¸ºè¿™ä¸¤ä¸ªæœåŠ¡éƒ½å ç”¨èµ„æºï¼Œå¹¶ä¸” SecondNameNode æ˜¯è¾…åŠ© NameNode çš„ï¼Œå¦‚æœè£…æ€åŒä¸€å°æœåŠ¡å™¨ï¼Œä¸¤ä¸ªä¼šåŒæ—¶å®•æœºã€‚

ç»¼åˆä¸Šè¿°è§„èŒƒï¼Œæœ€ç»ˆçš„å„èŠ‚ç‚¹æœåŠ¡å¦‚ä¸‹ï¼š

|      |       Hadoop102       |             Hadoop103            |          Hadoop104          |
| :--: | :-------------------: | :------------------------------: | :-------------------------: |
| HDFS | **NameNode**ï¼›DataNode |             DataNode             | **SecondNameNode**ï¼›DataNode |
| YARN |      NodeManager      | **ResourcesManager**ï¼›NodeManager |         NodeManager         |

**Hadoop é…ç½®æ–‡ä»¶**

Hadoop çš„é…ç½®æ–¹å¼æœ‰å››ç§ï¼šé»˜è®¤é…ç½®ã€æ‰‹åŠ¨é…ç½®ã€ç¨‹åºé…ç½®æ–‡ä»¶ã€ç¨‹åºä¸­é…ç½®ï¼Œä¼˜å…ˆçº§ä¾æ¬¡é€’å¢ï¼Œåœ¨è¿™é‡Œå…ˆä»‹ç»å‰ä¸¤ç§é…ç½®æ–¹å¼ã€‚

Hadoop çš„å„ä¸ªç»„ä»¶å¦‚æœæ²¡æœ‰è¿›è¡Œæ‰‹åŠ¨é…ç½®çš„å±æ€§å°†è¿›è¡Œé»˜è®¤é…ç½®ï¼Œå¦‚æœæƒ³è¦æŸ¥çœ‹é»˜è®¤é…ç½®å¯ä»¥åœ¨ `$Hadoop_HOME/share/Hadoop` ä¸‹æ‰¾åˆ° commonã€hdfsã€yarn ä¸‰ä¸ªæ–‡ä»¶å¤¹ï¼Œé‡Œè¾¹æœ‰å¯¹åº”çš„ jar æ–‡ä»¶ï¼Œè§£å‹å³å¯çœ‹åˆ°é»˜è®¤çš„é…ç½®æ–‡ä»¶ã€‚

æ‰‹åŠ¨çš„é…ç½®æ–‡ä»¶åœ¨ `$Hadoop_HOME/etc/Hadoop` ä¸‹ï¼Œå¸¸ç”¨çš„æœ‰å››ä¸ªé…ç½®æ–‡ä»¶ï¼š

* core-site.xmlï¼šåŒ…å«Hadoopæ ¸å¿ƒç»„ä»¶ï¼ˆå¦‚HDFSå’ŒYARNï¼‰çš„å…¬å…±é…ç½®ä¿¡æ¯ã€‚
* hdfs-site.xmlï¼šåŒ…å«HDFSç»„ä»¶çš„ç‰¹å®šé…ç½®ä¿¡æ¯ã€‚
* yarn-site.xmlï¼šåŒ…å«YARNç»„ä»¶çš„ç‰¹å®šé…ç½®ä¿¡æ¯ã€‚
* mapred-site.xmlï¼šåŒ…å«MapReduceç»„ä»¶çš„ç‰¹å®šé…ç½®ä¿¡æ¯ã€‚

![image-20230107095151425](Hadoop.assets/image-20230107095151425.png)

**core-site.xml**

```xml
<configuration>
	<!--é…ç½® NameNode åœ°å€-->
	<property>
		<name>fs.defaultFS</name>
		<value>hdfs://Hadoop102:8020</value>
	</property>
	<!--é…ç½® data çš„å­˜å‚¨è·¯å¾„-->
	<property>
		<name>Hadoop.tmp.dir</name>
		<value>/home/zh/Hadoop_data</value>
	</property>
</configuration>
```

**hdfs-site.xml**

```xml
<configuration>
	<property>
		<!--é…ç½® NameNode å¯¹ç®¡ç†å‘˜è®¿é—®çš„ web åœ°å€å’Œç«¯å£å·-->
		<name>dfs.namemode.http-address</name>
		<value>Hadoop102:9870</value>
	</property>
	<property>
		<!--é…ç½® SecondNameNode å¯¹ç®¡ç†å‘˜è®¿é—®çš„ web åœ°å€å’Œç«¯å£å·-->
		<name>dfs.namenode.secondary.http-address</name>
		<value>Hadoop104:9868</value>
	</property>
</configuration>
```

**yarn-site.xml**

```xml
<configuration>
	<property>
		<!--æŒ‡å®š mapreduce èµ° shuffle-->
		<name>yarn.nodemanager.aux-services</name>
		<value>mapreduce_shuffle</value>
	</property>
	<property>
		<!--æŒ‡å®š resourcemanager æœåŠ¡å™¨-->
		<name>yarn.resourcemanager.hostname</name>
		<value>Hadoop103</value>
	</property>
	<property>
		<!--ç¯å¢ƒå˜é‡çš„ç»§æ‰¿-->
		<!--å¬è¯´è¿™ä¸ªæ˜¯ä¸€ä¸ª 3.1.3 çš„ bugï¼Œåç»­ç‰ˆæœ¬ä¸éœ€è¦åœ¨é…ç½®è¿™ä¸ª-->
		<name>yarn.nodemanager.env-whitelist</name>
		<value>JAVA_HOME,Hadoop_COMMON_HOME,Hadoop_HDFS_HOME,Hadoop_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,Hadoop_YARN_HOME,Hadoop_MAPRED_HOME</value>
	</property>
</configuration>
```

**mapperd\_site.xml**

```xml
<configuration>
	<!--æŒ‡å®š mapperreduce ç¨‹åºè¿è¡Œåœ¨ YARN ä¸Š-->
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
</configuration>
```

**works**

é…ç½®é›†ç¾¤æœåŠ¡å™¨çš„ hostnameã€‚\*\*æ³¨æ„ï¼š\*\*è¿™é‡Œä¸èƒ½æœ‰ç©ºæ ¼å’Œç©ºè¡Œ

```shell
Hadoop102
Hadoop103
Hadoop104
```

#### å¯åŠ¨é›†ç¾¤

**åˆå§‹åŒ– NameNode å‚¨å­˜ç©ºé—´**

åœ¨ NameNode ç¬¬ä¸€æ¬¡ä½¿ç”¨ä¹‹å‰éœ€è¦å¯¹å‚¨å­˜ç©ºé—´ï¼ˆé…ç½®çš„æ–‡ä»¶å¤¹ï¼‰è¿›è¡Œåˆå§‹åŒ–æ“ä½œï¼Œç›¸å½“äºæ–°ç¡¬ç›˜ä½¿ç”¨ä¹‹å‰éœ€è¦è¿›è¡Œæ ¼å¼åŒ–åˆ†åŒºä¸€æ ·ã€‚å¦‚æœæ²¡æœ‰æŠ¥é”™è¡¨ç¤ºåˆå§‹åŒ–æˆåŠŸã€‚åªéœ€è¦å¯¹ NameNode æœåŠ¡å™¨è¿›è¡Œåˆå§‹åŒ–æ“ä½œã€‚

```shell
> hdfs namenode -fromat
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = Hadoop102/192.168.1.102
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 3.1.3
......
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at Hadoop102/192.168.1.102
************************************************************/
```

åˆå§‹åŒ–å®Œæˆä¹‹åå°†ä½ é…ç½®çš„ hdfs çš„å­˜å‚¨ç›®å½•ä¸‹ç”Ÿæˆä¸€äº›æ–‡ä»¶ï¼Œä¼šåœ¨ `dfs/name/current` æ–‡ä»¶å¤¹ä¸‹ç”Ÿæˆ fsimage å’Œ editor æ–‡ä»¶ï¼Œç”¨æ¥ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶çš„ä¿¡æ¯ï¼Œå…·ä½“çš„åŠŸèƒ½å°†åœ¨åç»­è®²è§£ã€‚

é™¤äº†ç”¨æ¥å­˜æ”¾æ–‡ä»¶ä¿¡æ¯çš„ç›®å½•ä¹‹å¤–ï¼Œè¿˜ä¼šå† `dfs/data/current/VERSION` ä¸­ç”Ÿæˆæ–‡ä»¶æœ¬æ¬¡åˆå§‹åŒ–çš„æ–‡ä»¶ç³»ç»Ÿçš„ IDï¼ˆdatanodeUuidï¼‰ï¼Œåªæœ‰æ–‡ä»¶ç³»ç»Ÿ ID ç›¸åŒçš„ namenode å’Œ datanode èŠ‚ç‚¹æ‰èƒ½å…±åŒå·¥ä½œç»„æˆé›†ç¾¤ï¼Œå¦‚æœ ID ä¸ä¸€æ ·å°†ä¸èƒ½ç»„æˆé›†ç¾¤ï¼Œè¿™æ ·è®¾è®¡å¯ä»¥é˜²æ­¢æ–‡ç”±äºæ–‡ä»¶ç³»ç»Ÿçš„å†…å®¹ä¸åŒ¹é…ï¼ˆæ¯”å¦‚ä¸€å°æœåŠ¡å™¨é‡æ–°åˆå§‹åŒ–äº†å·¥ä½œç©ºé—´ï¼Œä½†æ˜¯å…¶ä»–æœåŠ¡å™¨è¿˜æœ‰å†å²æ•°æ®ï¼‰é€ æˆæ–‡ä»¶æŸåã€‚

```shell
> cat VERSION 
#Sun Jan 08 17:35:17 CST 2023
datanodeUuid=b5867d24-c7d5-4e54-abfb-44c8fa230f55
storageType=DATA_NODE
cTime=0
clusterID=CID-ce27dce7-0766-4fec-b536-b0965cf23a2d
layoutVersion=-57
storageID=DS-156883f6-ce5b-44de-99f0-f7f26fbe6561
```

**å¯åŠ¨**

```shell
> start-dfs.sh 
Starting namenodes on [Hadoop102]
Starting datanodes
Hadoop104: WARNING: /home/zh/bin/Hadoop-3.1.3/logs does not exist. Creating.
Hadoop103: WARNING: /home/zh/bin/Hadoop-3.1.3/logs does not exist. Creating.
Starting secondary namenodes [Hadoop104]

> jps
30344 DataNode
30666 Jps
30173 NameNode
```

é›†ç¾¤å¯åŠ¨æˆåŠŸä¹‹ååˆ†åˆ«åœ¨ä¸åŒçš„æœåŠ¡å™¨æ‰§è¡Œ jps å‘½ä»¤ï¼Œå¹¶äºé›†ç¾¤çš„è§„åˆ’åšå¯¹æ¯”ï¼Œçœ‹æ˜¯å¦å¯åŠ¨æˆåŠŸã€‚

åœ¨æµè§ˆå™¨è¾“å…¥ http://192.168.1.102:9870/ å¯ä»¥çœ‹åˆ°åˆšåˆšé…ç½®çš„ç®¡ç†å‘˜ web é¡µé¢ã€‚

![image-20230107211405379](Hadoop.assets/image-20230107211405379.png)

å¦å¤– YARN ä¹Ÿæä¾›ä¸€ä¸ª web è®¿é—®é¡µé¢ï¼ˆhttp://192.168.1.103:8088/clusterï¼‰ï¼Œå¯ä»¥çœ‹åˆ°æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡çš„è¯¦ç»†ä¿¡æ¯ã€‚

![image-20230109090342631](Hadoop.assets/image-20230109090342631.png)

#### ç®€å•æµ‹è¯•

**åˆ›å»ºæ–‡ä»¶å¤¹**

å¯¹äº Hadoop çš„æ–‡ä»¶ç³»ç»Ÿï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œçš„æ–¹å¼è¿›è¡Œåˆ›å»ºï¼Œåˆ é™¤ï¼Œç§»åŠ¨ç­‰å¸¸è§çš„æ–‡ä»¶æ“ä½œã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸‹è¾¹çš„å‘½ä»¤åœ¨ Hadoop ä¸­åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ï¼š

```shell
> Hadoop fs -mkdir /wcinput
```

æ‰§è¡Œå®Œæ¯•ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ Hadoop web ç®¡ç†é¡µé¢çš„ `Utilities>Browse the file ssystem` ä¸­çœ‹åˆ°åˆšåˆšåˆ›å»ºçš„æ–‡ä»¶å¤¹ã€‚

![image-20230109091012028](Hadoop.assets/image-20230109091012028.png)

**æ–‡ä»¶ä¸Šä¼ **

åˆ›å»ºå®Œæ–‡ä»¶å¤¹ä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œçš„æ–¹å¼å°†æœ¬åœ°çš„æ–‡ä»¶ä¸Šä¼ åˆ°æ”¹æ–‡ä»¶å¤¹ä¸­ã€‚

```shell
> Hadoop fs -put wcinput/word.txt /wcinput
```

ä¸Šä¼ å®Œæˆåï¼Œæ‰“å¼€ HDFS çš„ web é¡µé¢ï¼Œæˆ‘ä»¬è¿›å…¥ /wcinput æ–‡ä»¶å¤¹å¯ä»¥çœ‹åˆ°åˆšåˆšçš„æ–‡ä»¶å¤¹ï¼Œå¯ä»¥ç‚¹å‡»çœ‹åˆ°æ–‡ä»¶çš„è¯¦æƒ…ï¼Œå¯ä»¥é¢„è§ˆå’Œä¸‹è½½ã€‚å¦‚æœç‚¹å‡»å®Œä¸‹è½½æç¤ºé¡µé¢æ‰“ä¸å¼€ï¼Œè¯·é…ç½®ä¸»æœºçš„ host æ–‡ä»¶ï¼Œè®¾ç½®å„ä¸ªæœåŠ¡å™¨ hostname å¯¹åº”çš„ ip åœ°å€ã€‚

![image-20230109092135058](Hadoop.assets/image-20230109092135058.png)

ä¸Šä¼ åˆ°é›†ç¾¤çš„æ–‡ä»¶å°†ä¼šä¿å­˜åˆ°é…ç½®çš„ç›®å½•çš„ data æ–‡ä»¶å¤¹ä¸‹ï¼Œå¹¶ä¸”æ–‡ä»¶ä¼šè¢«åˆ†å—ï¼Œå°æ–‡ä»¶å¯èƒ½åªå ç”¨ä¸€ä¸ªæ–‡ä»¶å¿«ï¼Œå¤§çš„æ–‡ä»¶ä¼šè¢«åˆ‡å‰²æˆå¤šä¸ªæ–‡ä»¶å¿«è¿›è¡Œå­˜å‚¨ã€‚é™¤æ­¤ä¹‹å¤–ï¼ŒåŒä¸€ä¸ªæ–‡ä»¶è¿˜ä¼šè¢«å­˜å‚¨åœ¨å¤šä¸ªæœåŠ¡å™¨ä¸Šï¼Œä»¥ä¿è¯æ–‡ä»¶çš„å¯é æ€§ã€‚

**é›†ç¾¤ç‰ˆ wordcount**

ä¸Šè¾¹æ‰§è¡Œçš„ wordcount ç¨‹åºæ˜¯åœ¨æœ¬åœ°æ¨¡å¼ä¸‹è¿è¡Œçš„ï¼Œå¹¶æ²¡æœ‰ä½¿ç”¨é›†ç¾¤ï¼Œåªæ˜¯ç”¨æ¥è¿›è¡Œç®€å•çš„æµ‹è¯•ã€‚wordcount ç¨‹åºåŒæ ·èƒ½å¤Ÿè¿è¡Œåœ¨é›†ç¾¤ä¸Šç”± yarn è°ƒåº¦ã€‚å¯ä»¥æ‰§è¡ŒåŒæ ·çš„å‘½ä»¤æ¥æ‰§è¡Œï¼Œä½†æ˜¯è¦å°†è¾“å…¥è¾“å‡ºç›®å½•æ¢æˆé›†ç¾¤çš„ç›®å½•ï¼Œå…·ä½“å‘½ä»¤å¦‚ä¸‹ï¼š

```shell
> Hadoop jar bin/Hadoop-3.1.3/share/Hadoop/mapreduce/Hadoop-mapreduce-examples-3.1.3.jar wordcount /wcinput /wcoutput
2023-01-09 09:47:02,420 INFO client.RMProxy: Connecting to ResourceManager at Hadoop103/192.168.1.103:8032
2023-01-09 09:47:02,597 INFO mapreduce.JobResourceUploader: Disabling Erasure Coding for path: /tmp/Hadoop-yarn/staging/zh/.staging/job_1673225993091_0001
2023-01-09 09:47:02,656 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2023-01-09 09:47:02,745 INFO input.FileInputFormat: Total input files to process : 1
2023-01-09 09:47:02,762 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2023-01-09 09:47:02,797 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2023-01-09 09:47:02,818 INFO mapreduce.JobSubmitter: number of splits:1
2023-01-09 09:47:02,958 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false
2023-01-09 09:47:02,990 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1673225993091_0001
2023-01-09 09:47:02,991 INFO mapreduce.JobSubmitter: Executing with tokens: []
2023-01-09 09:47:03,097 INFO conf.Configuration: resource-types.xml not found
2023-01-09 09:47:03,097 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.
2023-01-09 09:47:03,191 INFO impl.YarnClientImpl: Submitted application application_1673225993091_0001
2023-01-09 09:47:03,210 INFO mapreduce.Job: The url to track the job: http://Hadoop103:8088/proxy/application_1673225993091_0001/
2023-01-09 09:47:03,210 INFO mapreduce.Job: Running job: job_1673225993091_0001
2023-01-09 09:47:08,269 INFO mapreduce.Job: Job job_1673225993091_0001 running in uber mode : false
2023-01-09 09:47:08,270 INFO mapreduce.Job:  map 0% reduce 0%
2023-01-09 09:47:11,295 INFO mapreduce.Job:  map 100% reduce 0%
2023-01-09 09:47:15,310 INFO mapreduce.Job:  map 100% reduce 100%
2023-01-09 09:47:16,319 INFO mapreduce.Job: Job job_1673225993091_0001 completed successfully
2023-01-09 09:47:16,377 INFO mapreduce.Job: Counters: 53
......
```

ç¨‹åºçš„éƒ¨åˆ†è¾“å‡ºå¦‚ä¸Šï¼Œåœ¨ä»»åŠ¡è¿è¡Œçš„æ—¶å€™ï¼Œå¯ä»¥é€šè¿‡ yarn çš„ web é¡µé¢æŸ¥çœ‹æ­£åœ¨è¿è¡Œçš„ä»»åŠ¡çš„è¯¦æƒ…ï¼Œå¦‚ä¸‹å…¥æ‰€ç¤ºï¼š

![image-20230109094750265](Hadoop.assets/image-20230109094750265.png)

è¿è¡Œç»“æŸåï¼Œå°†åœ¨ HDFS ç³»ç»Ÿä¸­äº§ç”Ÿç›®æ ‡æ–‡ä»¶å¤¹æ¥å­˜æ”¾æ‰§è¡Œç»“æœï¼Œå†…å®¹ä¸æœ¬åœ°è¿è¡Œçš„ç»“æœç›¸åŒã€‚

#### é…ç½®å†å²æœåŠ¡å™¨

**ä»€ä¹ˆæ˜¯å†å²æœåŠ¡å™¨**

åœ¨åˆšåˆš wordcount çš„æµ‹è¯•ä¸­ï¼Œyarn çš„ web é¡µé¢å¹¶ä¸èƒ½æ˜¾ç¤ºå†å²ä»»åŠ¡ï¼Œè¿™æ˜¯å› ä¸º yarn åªæ˜¯å¤æ‚è€Œè°ƒåº¦ï¼Œå¹¶ä¸ä¼šè®°å½•å†å²ä»»åŠ¡ã€‚å¦‚æœæƒ³è¦èƒ½å¤Ÿä¿å­˜å†å²ä»»åŠ¡ï¼Œå¯ä»¥é…ç½®å†å²ä»»åŠ¡æœåŠ¡å™¨ï¼Œå®ƒå¯ä»¥åœ¨ yarn è¿è¡Œæ—¶å°†ä»»åŠ¡çš„è¯¦æƒ…è®°å½•ä¸‹æ¥ï¼Œä½†æ˜¯å¹¶ä¼šä¸è®°å½•ä»»åŠ¡çš„è¿è¡Œæ—¥å¿—ã€‚

**é…ç½®**

å¯ä»¥é…ç½® yarn æ¥å¼€å¯å†å²ä»»åŠ¡æœåŠ¡å™¨ï¼Œåœ¨ `$Hadoop_HOME/etc/Hadoop/mapred-site.xml` ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®ï¼š

```xml
<property>
	<!--é…ç½®å†å²æœåŠ¡å™¨ç«¯çš„åœ°å€-->
	<name>mapreduce.jobhistory.address</name>
	<value>Hadoop102:10020</value>
</property>
<property>
	<!--é…ç½®å†å²æœåŠ¡å™¨çš„ web åœ°å€-->
	<name>mapreduce.jobhistory.webapp.address</name>
	<value>Hadoop102:19888</value>
</property>
```

é…ç½®å®Œæˆä¹‹åå°†æ–°çš„é…ç½®ä¿¡æ¯è¿›è¡Œåˆ†å‘ã€‚æœ€åé‡å¯ yarn å¹¶é€šè¿‡å¦‚ä¸‹å‘½ä»¤æ¥å¯åŠ¨å†å²æœåŠ¡å™¨ï¼š

```shell
> mapred --daemon start historyserver

> jps
13584 NameNode
13761 DataNode
26708 NodeManager
27657 JobHistoryServer
27722 Jps
```

é‡æ–°æ‰§è¡Œåˆšåˆšçš„ wordcount ç¨‹åºï¼Œå¯ä»¥åœ¨ yarn çš„é¡µé¢çœ‹åˆ°æœ€æ–°çš„ä»»åŠ¡ï¼Œå°±ç®—åˆ·æ–°é¡µé¢ä¹Ÿèƒ½å¤ŸæŸ¥çœ‹ä»»åŠ¡çš„è¯¦æƒ…ã€‚

#### é…ç½®æ—¥å¿—èšé›†åŠŸèƒ½

**ä»€ä¹ˆæ˜¯æ—¥å¿—èšé›†**

åˆšåˆšé…ç½®å®Œæˆäº†å†å²ä»»åŠ¡æœåŠ¡å™¨ï¼Œä½†æ˜¯ä»ç„¶ä¸èƒ½ä¿ç•™ä»»åŠ¡è¿è¡Œçš„è¯¦ç»†æ—¥å¿—ï¼Œå¹¶ä¸”æ•´ä¸ªé›†ç¾¤åœ¨è¿è¡Œçš„è¿‡ç¨‹ä¸­ä¹Ÿä¼šäº§ç”Ÿå„ç§å„æ ·çš„æ—¥å¿—å­˜å‚¨åœ¨è‡ªå·±çš„æœåŠ¡å™¨ä¸Šï¼Œæ—¥å¿—èšé›†åŠŸèƒ½å°±æ˜¯å°†æ‰€æœ‰æœåŠ¡å™¨çš„æ—¥å¿—èšé›†åœ¨ä¸€èµ·ï¼Œé€šè¿‡ web å‘ç®¡ç†äººå‘˜å±•ç¤ºã€‚

**é…ç½®**

åœ¨ `$Hadoop_HOME/etc/Hadoop/yarn-site.xml` ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®æ¥å¼€å¯æ—¥å¿—èšé›†åŠŸèƒ½ï¼š

```xml
<property>
    <!--å¼€å¯æ—¥å¿—èšé›†åŠŸèƒ½-->
    <name>yarn.log-aggregation-enable</name>
    <value>true</value>
</property>
<property>
    <!--è®¾ç½®å†å²æœåŠ¡å™¨çš„åœ°å€-->
    <name>yarn.log.server.url</name>
    <value>http://Hadoop102:19888/jobhistory/logs</value>
</property>
<property>
    <!--è®¾ç½®æ—¥å¿—ä¿ç•™ 7 å¤©-->
    <name>yarn.log.aggregation.retain-seconds</name>
    <value>604800</value>
</property>
```

ç„¶åè¦é‡å¯ yarn å’Œ jobhistory æœåŠ¡å™¨ã€‚

```shell
> mapred --deamon stop jobhistory
> stop-yarn.sh

> mapred --deamon start jobhistory
> start-yarn.sh
```

é‡å¯å®Œæˆä¹‹ååœ¨è¿è¡Œæ–°çš„ä»»åŠ¡å°†ä¼šæ”¶é›†æ—¥å¿—ï¼Œå¯ä»¥é€šè¿‡å†å²ä»»åŠ¡æœåŠ¡å™¨çš„ logs æŒ‰é’®è¿›è¡ŒæŸ¥çœ‹ã€‚

![image-20230112102055804](Hadoop.assets/image-20230112102055804.png)

#### å„ç§å¯åŠ¨åœæ­¢æ–¹å¼æ€»ç»“

**é›†ç¾¤**

å¯åŠ¨/åœæ­¢ hdfs/yarnï¼š

```shell
> start/stop-dfs/yarn.sh
```

**å•èŠ‚ç‚¹**

```shell
> hdfs --daemon start/stop namenode/datanode/secondnamenode
```

**è„šæœ¬**

å¦‚æœæœåŠ¡å™¨å¾ˆå¤šï¼Œæ‰‹åŠ¨é‡å¯åŠ¨å•èŠ‚ç‚¹å¾ˆéº»çƒ¦ï¼Œå¯ä»¥é€šè¿‡ä¸‹è¾¹çš„è„šæœ¬ï¼Œå°†ä¸€æ¡å‘½ä»¤åˆ†å‘ç»™æ‰€æœ‰æœåŠ¡å™¨æ‰§è¡Œ

```shell
#!/bin/bash

for Hadoop in Hadoop102 Hadoop103 Hadoop104;do
        echo "=======================" $Hadoop "======================="
        ssh $Hadoop $@
done
```

#### å¸¸è§ç«¯å£å·

|        ç«¯å£å·       | Hadoop2.x |     Hadoop3.x     |
| :--------------: | :-------: | :---------------: |
|   NameNodeå†…éƒ¨é€šä¿¡   |  8020/900 | **8020**/900/9820 |
| NameNode HTTP UI |   50070   |        9870       |
| MapReduce æŸ¥çœ‹æ‰§è¡Œä»»åŠ¡ |    8088   |        8088       |
|     å†å²ä»»åŠ¡æœåŠ¡å™¨é€šä¿¡    |   19888   |       19888       |

#### æ—¶é—´åŒæ­¥

åœ¨é›†ç¾¤å†…éƒ¨éœ€è¦è¿›è¡Œæ—¶é—´åŒæ­¥ï¼Œå¦‚æœé›†ç¾¤èƒ½å¤Ÿè¿æ¥å¤–ç½‘ä¼šè‡ªåŠ¨è¿›è¡Œæ—¶é—´åŒæ­¥ï¼Œå¦‚æœä¸èƒ½è¿æ¥å¤–ç½‘ï¼Œéœ€è¦ä»¥ä¸€å°æœåŠ¡å™¨ä¸ºå‡†ï¼Œå¯¹å…¶ä»–æœåŠ¡å™¨è¿›è¡ŒåŒæ­¥ã€‚å…·ä½“çš„é…ç½®è¿‡ç¨‹éƒ¨åˆ†å°±ä¸å†™äº†ã€‚

#### å¸¸è§é”™è¯¯çš„è§£å†³æ–¹æ¡ˆ

**DFS webé¡µé¢æŠ¥é”™ã€‚**

**æŠ¥é”™ä¿¡æ¯**

> Failed to retrieve data from /webhdfs/v1/?op=LISTSTATUS: Server Error

æŸ¥çœ‹ logs ä¸‹çš„ NameNode æ—¥å¿—æ–‡ä»¶ï¼ŒæŠ¥é”™ä¿¡æ¯å¦‚ä¸‹ï¼š

> 2023-01-07 21:28:38,045 WARN org.eclipse.jetty.servlet.ServletHandler: Error for /webhdfs/v1/ java.lang.NoClassDefFoundError: javax/activation/DataSource at com.sun.xml.bind.v2.model.impl.RuntimeBuiltinLeafInfoImpl.(RuntimeBuiltinLeafInfoImpl.java:457) at com.sun.xml.bind.v2.model.impl.RuntimeTypeInfoSetImpl.(RuntimeTypeInfoSetImpl.java:65) at com.sun.xml.bind.v2.model.impl.RuntimeModelBuilder.createTypeInfoSet(RuntimeModelBuilder.java:133) at com.sun.xml.bind.v2.model.impl.RuntimeModelBuilder.createTypeInfoSet(RuntimeModelBuilder.java:85) at com.sun.xml.bind.v2.model.impl.ModelBuilder.(ModelBuilder.java:156) at com.sun.xml.bind.v2.model.impl.RuntimeModelBuilder.(RuntimeModelBuilder.java:93) at com.sun.xml.bind.v2.runtime.JAXBContextImpl.getTypeInfoSet(JAXBContextImpl.java:473) at com.sun.xml.bind.v2.runtime.JAXBContextImpl.(JAXBContextImpl.java:319) at com.sun.xml.bind.v2.runtime.JAXBContextImpl$JAXBContextBuilder.build(JAXBContextImpl.java:1170) at com.sun.xml.bind.v2.ContextFactory.createContext(ContextFactory.java:145) at com.sun.xml.bind.v2.ContextFactory.createContext(ContextFactory.java:236)

**åŸå› **

jdk-9 å¼€å§‹å¼ƒç”¨äº† [`java.activation`](http://openjdk.java.net/jeps/261#EE-modules) æ¨¡å—ï¼Œåˆ° jdk-11 å®Œå…¨è¢«åˆ é™¤äº†ï¼Œå¦‚æœ Hadoop ç‰ˆæœ¬æ¯”è¾ƒä½å¹¶ä¸” jdk ç‰ˆæœ¬é«˜å°±ä¼šæ‰¾ä¸åˆ°ä¾èµ–è€ŒæŠ¥é”™ã€‚

**ä¿®å¤**

æœ€ç®€å•çš„åŠæ³•æ˜¯é™çº§ jdk ä½¿ç”¨ï¼Œå¦‚æœæ˜¯ä½¿ç”¨ jdk-9 æˆ–è€… jdk-10 å¯ä»¥åœ¨ `$Hadoop_HOME/etc/Hadoop/Hadoop-env.sh` æ–‡ä»¶ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®æ¥å¯ç”¨ `java.activation` æ¨¡å—ã€‚

```shell
export Hadoop_OPTS="${Hadoop_OPTS} --add-modules java.activation "
```

å¦‚æœä½¿ç”¨ jdk-11 åŠä»¥ä¸Šçš„ç‰ˆæœ¬ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½ java.activation æ¨¡å—çš„ [jar](https://jcenter.bintray.com/javax/activation/javax.activation-api/1.2.0/javax.activation-api-1.2.0.jar) åŒ…ï¼Œç„¶åå­˜æ”¾åœ¨åˆé€‚çš„ä½ç½®ï¼Œæˆ‘æ˜¯åœ¨ $Hadoop\_HOME/lib ä¸‹æ–°å»ºäº†ä¸€ä¸ª dfs çš„æ–‡ä»¶å¤¹ï¼Œè¡¨ç¤ºè¿™æ˜¯ dfs çš„ä¾èµ–ã€‚ç„¶ååœ¨ $Hadoop\_HOME/etc/Hadoop/Hadoop-env.sh ä¸­å°†æ–°çš„æ–‡ä»¶ä¾èµ–è·¯å¾„æ·»åŠ è¿›å»ï¼Œæœ€åé‡å¯é›†ç¾¤å³å¯è§£å†³é—®é¢˜ã€‚

```shell
export Hadoop_CLASSPATH+="$Hadoop_HOME/lib/dfs/*.jar"
```

**éƒ¨åˆ† DataNode ä¸å¯åŠ¨**

**æŠ¥é”™ä¿¡æ¯**

ä¸ä¼šæŠ¥ä»»ä½•å¼‚å¸¸ï¼Œæˆ‘åœ¨æ—¥å¿—ä¹Ÿæ²¡æœ‰æ‰¾åˆ°æŠ¥é”™ä¿¡æ¯ï¼Œä½†æ˜¯å…·ä½“çš„è¡¨ç°å°±æ˜¯æ€»æ˜¯æœ‰ä¸€éƒ¨åˆ† DataNode èŠ‚ç‚¹ä¸å¯åŠ¨ï¼Œåœ¨é›†ç¾¤ä¿¡æ¯ä¸­ä¹Ÿçœ‹ä¸åˆ°å¯¹åº”çš„èŠ‚ç‚¹ï¼Œä¹Ÿæ²¡æœ‰ä»»ä½•å¼‚å¸¸ã€‚

**åŸå› **

å› ä¸º NameNode ä¼šæ¯æ¬¡åˆå§‹åŒ–ç³»ç»Ÿä¼šç”Ÿæˆ IDï¼Œå¦‚æœé‡å¤æ‰§è¡Œè¿‡åˆå§‹åŒ–æˆ–è€…åœ¨å¤šä¸ªæœåŠ¡å™¨ä¸Šè¿›è¡Œåˆå§‹åŒ–ï¼Œå°†ä¼šé€ æˆ ID ä¸åŒ¹é…ï¼ŒèŠ‚ç‚¹ä¸å¯åŠ¨ã€‚

**ä¿®å¤**

å…³é—­é›†ç¾¤ï¼Œæ¸…ç©ºæ‰€æœ‰èŠ‚ç‚¹ä¸Šç”¨æ¥ä¿å­˜æ•°æ®çš„æ–‡ä»¶å¤¹å’Œ logs æ–‡ä»¶å¤¹ï¼Œç„¶åé‡æ–°åˆå§‹åŒ–ç©ºé—´ï¼Œæœ€åå¯åŠ¨é›†ç¾¤å³å¯ã€‚

### HDFS

#### HDFS ç®€ä»‹

**ä¼˜ç¼ºç‚¹**

![image-20230112115326264](Hadoop.assets/image-20230112115326264.png)

![image-20230112115700088](Hadoop.assets/image-20230112115700088.png)

**HDFS ç»„æˆ**

![image-20230112120624509](Hadoop.assets/image-20230112120624509.png)

**æ–‡ä»¶å—å¤§å°**

![image-20230112121622411](Hadoop.assets/image-20230112121622411.png)

#### å‘½ä»¤è¡Œæ“ä½œ

```shell
> Hadoop fs
Usage: Hadoop fs [generic options]
......
The general command line syntax is:
command [genericOptions] [commandOptions]
```

```shell
> hdfs fs
Usage: Hadoop fs [generic options]
......
The general command line syntax is:
command [genericOptions] [commandOptions]
```

è¿™ä¸¤ä¸ªå‘½ä»¤æ˜¯ä¸€æ ·çš„ï¼Œä¼šä½¿ç”¨ä¸€ä¸ªå°±å¯ä»¥ã€‚æˆ‘æ¯”è¾ƒå–œæ¬¢ `Hadoop fs` ã€‚ä¸€äº›å¸¸ç”¨çš„å‚æ•°å¦‚ä¸‹ï¼Œå¯¹äºè¿™äº›å‚æ•°è¦ç†Ÿè®°ï¼Œè¿™äº›å‘½ä»¤æ¯”è¾ƒç®€å•ï¼Œä¸ linux å‘½ä»¤æ¯”è¾ƒæ¥è¿‘ï¼Œå°±ä¸è¿›è¡Œä¸€ä¸€æ¼”ç¤ºäº†ã€‚

```shell
[-appendToFile <localsrc> ... <dst>]
[-cat [-ignoreCrc] <src> ...]
[-chgrp [-R] GROUP PATH...]
[-chmod [-R] <MODE[,MODE]... | OCTALMODE> PATH...]
[-chown [-R] [OWNER][:[GROUP]] PATH...]
[-copyFromLocal [-f] [-p] [-l] [-d] [-t <thread count>] <localsrc> ... <dst>]
[-copyToLocal [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
[-count [-q] [-h] [-v] [-t [<storage type>]] [-u] [-x] [-e] <path> ...]
[-cp [-f] [-p | -p[topax]] [-d] <src> ... <dst>]
[-find <path> ... <expression> ...]
[-get [-f] [-p] [-ignoreCrc] [-crc] <src> ... <localdst>]
[-head <file>]
[-help [cmd ...]]
[-ls [-C] [-d] [-h] [-q] [-R] [-t] [-S] [-r] [-u] [-e] [<path> ...]]
[-mkdir [-p] <path> ...]
[-moveFromLocal <localsrc> ... <dst>]
[-moveToLocal <src> <localdst>]
[-mv <src> ... <dst>]
[-put [-f] [-p] [-l] [-d] <localsrc> ... <dst>]
[-rm [-f] [-r|-R] [-skipTrash] [-safely] <src> ...]
[-rmdir [--ignore-fail-on-non-empty] <dir> ...]
[-tail [-f] [-s <sleep interval>] <file>]
```

#### API æ“ä½œ

**å®‰è£…**

å¦‚æœä½¿ç”¨ window è¿›è¡Œ Hadoop çš„å¼€å‘å·¥ä½œï¼Œéœ€è¦å®‰è£…ç‰¹æ®Šçš„è¡¥ä¸æ‰èƒ½ä½¿ç”¨ï¼Œå…·ä½“çš„å®‰è£…è¿‡ç¨‹æˆ‘å°±ä¸æ¼”ç¤ºäº†ï¼Œå¤§æ¦‚çš„æµç¨‹å°±æ˜¯é¦–å…ˆä¸‹è½½ Hadoop çš„ windows ç‰ˆï¼Œç„¶åé…ç½®ç¯å¢ƒå˜é‡ï¼Œæœ€åä½¿ç”¨ winUtils è¿›è¡Œæ‰“è¡¥ä¸ï¼ŒwinUtils è¡¥ä¸çš„ç‰ˆæœ¬éœ€è¦ä¸ Hadoop çš„ç‰ˆæœ¬ç›¸åŒ¹é…æ‰å¯ä»¥ã€‚

**åˆ›å»ºå·¥ç¨‹**

æ­£å¸¸åˆ›å»ºä¸€ä¸ª maven å·¥ç¨‹ï¼Œç„¶åæ·»åŠ ä¾èµ–å’Œ log4j çš„é…ç½®æ–‡ä»¶ã€‚

maven ä¾èµ–å¦‚ä¸‹ï¼š

```xml
<dependencies>
    <!-- https://mvnrepository.com/artifact/org.apache.Hadoop/Hadoop-client -->
    <dependency>
        <groupId>org.apache.Hadoop</groupId>
        <artifactId>Hadoop-client</artifactId>
        <version>3.3.4</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/org.apache.Hadoop/Hadoop-common -->
    <dependency>
        <groupId>org.apache.Hadoop</groupId>
        <artifactId>Hadoop-common</artifactId>
        <version>3.3.4</version>
    </dependency>
    <!-- https://mvnrepository.com/artifact/org.apache.logging.log4j/log4j-core -->
    <dependency>
        <groupId>org.slf4j</groupId>
        <artifactId>slf4j-log4j12</artifactId>
        <version>1.7.30</version>
    </dependency>
    <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>4.13.2</version>
        <scope>compile</scope>
    </dependency>
</dependencies>
```

log4j çš„é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š

```properties
log4j.rootLogger=INFO, stdout
log4j.appender.stdout=org.apache.log4j.ConsoleAppender
log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
log4j.appender.stdout.layout.ConversionPattern=%d %p[%c] - %m%n
log4j.appender.logfile=org.apache.log4j.FileAppender
log4j.appender.logfile.File=target/spring.log
log4j.appender.logfile.layout=org.apache.log4j.PatternLayout
log4j.appender.logfile.layout.ConversionPattern=%d %p [%c] - %m%n
```

**ä»£ç ç¤ºä¾‹**

é€šç”¨å¥—è·¯ï¼šåƒè¿™ç§éœ€è¦å¯¹è¿œç¨‹æœåŠ¡å™¨è¿›è¡Œæ“ä½œçš„ï¼Œä¸€èˆ¬çš„æ“ä½œæµç¨‹å°±æ˜¯å…ˆè·å–è¿æ¥ï¼Œç„¶åè¿›è¡Œæ­£å¸¸çš„æ“ä½œï¼Œæœ€åå…³é—­è¿æ¥å³å¯ã€‚åœ¨æ‰§è¡Œä»£ç ä¹‹å‰ä¸€å®šè¦ä¿è¯ä½ çš„é›†ç¾¤æ˜¯åœ¨æ­£å¸¸è¿è¡Œçš„ã€‚

**å¯¼åŒ…**

åœ¨è¿›è¡Œ api æ“ä½œæ—¶ï¼Œç”±ä¸€äº›é‡å¤çš„ç±»åï¼Œå¯¹äºæ–°æ‰‹ç»Ÿä¸€æé”™ï¼Œæœ¬èŠ‚ä»£ç ä½¿ç”¨çš„åŒ…ä¿¡æ¯å¦‚ä¸‹ï¼š

```java
import org.apache.Hadoop.conf.Configuration;
import org.apache.Hadoop.fs.FileSystem;
import org.apache.Hadoop.fs.Path;

import java.net.URI;
```

**è¿æ¥çš„è·å–ä¸å…³é—­**

```java
public void before() throws Exception {
    URI uri = new URI("hdfs://Hadoop102:8020");
    Configuration configuration = new Configuration();
    fs = FileSystem.get(uri, configuration, "zh");
}
public void after() throws Exception {
    fs.close();
}
```

**å¸¸è§æ“ä½œ**

```java
public void mkdir() throws Exception {
    fs.mkdirs(new Path("/api_test"));
}

public void delete() throws Exception {
    fs.delete(new Path("/output"), true);
}

public void upload() throws Exception {
    fs.moveFromLocalFile(new Path("D:\\atar.gz"), new Path("/api_test"));
}

public void download() throws Exception {
    fs.copyToLocalFile(new Path("/api_test/a.tar.gz"), new Path("D:\\a.tar.gz"));
}

public void rename() throws Exception{
    fs.rename(new Path("/api_test/Hadoop-3.3.4.tar.gz"), new Path("/api_test/a.tar.gz"));
}

public void fileDetail() throws IOException {
    RemoteIterator<LocatedFileStatus> statusIterator
        = fs.listFiles(new Path("/api_test"), false);
    while (statusIterator.hasNext()) {
        LocatedFileStatus next = statusIterator.next();
        System.out.println(
            next.getPath() +
            "\t" + next.isDirectory() +
            "\t" + next.getPermission() +
            "\t" + next.getOwner() +
            "\t" + next.getGroup() +
            "\t" + next.getLen() +
            "\t" + next.getModificationTime() +
            "\t" + next.getReplication() +
            "\t" + next.getBlockSize() +
            "\t" + Arrays.toString(next.getBlockLocations())
        );
    }
}

public void isDir() throws IOException {
    FileStatus[] fileStatuses = fs.listStatus(new Path("/api_test"));
    for (FileStatus fileStatus : fileStatuses) {
        System.out.println((fileStatus.isDirectory() ? "" : "ä¸") + "æ˜¯ç›®å½•");
    }
}
```

ä¸Šè¾¹çš„åªæ˜¯äº›ç®€å•çš„æµ‹è¯•ï¼Œè‡³äºåŒåçš„å…¶ä»–æ–¹æ³•å’Œå…·ä½“çš„å‚æ•°è¯´æ˜å¯ä»¥çœ‹ä¸€çœ‹ APIï¼Œæ„Ÿè§‰è¿™äº›ä¸œè¥¿éƒ½ä¸æ˜¯å¾ˆéš¾ï¼Œä¸»è¦å°±æ˜¯ä¼šç”¨è¿™äº› API å°±å¯ä»¥ã€‚

**é…ç½®ä¼˜å…ˆçº§**

åœ¨ç¯å¢ƒæ­å»ºçš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬å·²ç»çŸ¥é“äº† Hadoop çš„ä¸¤ç§é…ç½®æ–‡ä»¶ï¼šé»˜è®¤é…ç½®å’Œè‡ªå®šä¹‰é…ç½®ã€‚å…¶ä¸­é»˜è®¤é…ç½®åœ¨å¯¹åº”çš„ jar åŒ…ä¸­ï¼Œè‡ªå®šä¹‰é…ç½®æ–‡ä»¶åœ¨ `$Hadoop_HOME/etc/Hadoop/` ä¸‹ã€‚

åœ¨å¼€å‘è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥åœ¨ resource æ–‡ä»¶å¤¹ä¸‹å»ºç«‹ç›¸åŒçš„é…ç½®æ–‡ä»¶åè¿›è¡Œé…ç½®ã€‚è¿˜å¯ä»¥é€šè¿‡ä¸Šè¿°ç¤ºä¾‹ä»£ç çš„ Configuration å¯¹è±¡æ¥è¿›è¡Œé…ç½®ã€‚è¿™å››ç§é…ç½®æ–¹å¼çš„ä¼˜å…ˆçº§ä¸ºï¼š

```
é»˜è®¤é…ç½® < æœä¹‰å™¨ä¸Šçš„é…ç½® < ç¨‹åº resources ä¸‹çš„é…ç½® < ä»£ç ä¸­é€šè¿‡ Configuration å¯¹è±¡çš„é…ç½®
```

#### HDFS è¯»å†™æµç¨‹

**å†™æµç¨‹**

![image-20230112194447774](Hadoop.assets/image-20230112194447774.png)

> 1. é¦–å…ˆå®¢æˆ·ç«¯å‘ NameNode è¯·æ±‚ä¸Šä¼ æ–‡ä»¶ï¼ŒNameNode è¿›è¡Œæƒé™ç­‰ä¸€ç³»åˆ—éªŒè¯ä¹‹åç›¸åº”æ˜¯å¦å¯ä»¥ä¸Šä¼ ã€‚
> 2.  å¦‚æœå¯ä»¥ä¸Šä¼ ï¼Œå®¢æˆ·ç«¯å°†å‘ NameNode è¯·æ±‚ä¸Šä¼ ç¬¬ä¸€å—æ•°æ®ï¼ŒNameNode å°†é€‰æ‹©é€‚å½“çš„æœåŠ¡å™¨èŠ‚ç‚¹è¿”å›ï¼Œå…·ä½“çš„åŸåˆ™æ–¹å¼å¦‚ä¸‹ï¼š
>
>     > 1. æœ¬åœ°å­˜å‚¨ä¼˜å…ˆ
>     > 2. æœºæ¶æ„ŸçŸ¥ï¼Œæ¥åŸåˆ™æœåŠ¡å™¨ï¼Œå…·ä½“è¿‡ç¨‹ä¸‹è¾¹è¯¦ç»†ä»‹ç»
>     > 3. æ ¹æ®èŠ‚ç‚¹çš„è´Ÿè½½å‡è¡¡æ¥åŠ¨æ€è°ƒèŠ‚
> 3.  å®¢æˆ·ç«¯å°†å’Œå„ä¸ªæœåŠ¡å™¨èŠ‚ç‚¹è¿›è¡Œåº”ç­”ï¼Œå¦‚æœåº”ç­”æˆåŠŸå°†å»ºç«‹é€šé“ï¼ˆåº”ç­”å’Œé€šé“éƒ½æ˜¯ä¸€æ¡é¾™ï¼Œå¦‚ä¸Šå›¾ï¼‰
>
>     > 1. é¦–å…ˆå°†æ–‡ä»¶æ‰“åŒ…æˆ 512byte çš„ chunkï¼Œå¹¶é™„åŠ  4byte çš„æ ¡éªŒä¿¡æ¯
>     > 2. å°† chunk æ”¾åœ¨ç¼“å†²åŒºï¼Œç¼“å†²åŒºæ»¡ 64k åå°†è¿›è¡Œå‘é€ï¼ŒæœåŠ¡å™¨æ”¶åˆ°æ•°æ®åŒ…åå°†è¿›è¡Œåº”ç­”
>     > 3. å‘å‡ºå»çš„ chunk å°†ä»å‘é€ç¼“å†²åŒºè½¬ç§»åˆ°åº”ç­”ç¼“å†²åŒºï¼Œåªæœ‰æ”¶åˆ°åº”ç­”çš„åŒ…æ‰è¢«åˆ é™¤ï¼Œå¦‚æœåº”ç­”å¤±è´¥å°†é‡æ–°å‘é€
> 4. ä¸€ä¸ª block å‘é€å®Œæˆä¹‹åå°†å‘ NameNode è¯·æ±‚ç¬¬äºŒä¸ª block çš„å‘é€ï¼Œé‡å¤æ­¥éª¤ 2 ç›´è‡³ç»“æŸ

**æœºæ¶æ„ŸçŸ¥**

**å®˜æ–¹ä»‹ç»**

å¯¹äºå‰¯æœ¬èŠ‚ç‚¹çš„é€‰æ‹© Hadoop é€šè¿‡æœºæ¶æ„ŸçŸ¥æ¥å®ç°ï¼Œå®˜æ–¹çš„ä»‹ç»é¡µé¢å¯ä»¥ç‚¹å‡»[è¿™é‡Œ](https://hadoop.apache.org/docs/r3.1.3/Hadoop-project-dist/Hadoop-hdfs/HdfsDesign.html#Data\_Replication)ï¼Œå®˜æ–¹ä»‹ç»å¦‚ä¸‹ï¼š

> #### Replica Placement: The First Baby Steps
>
> The placement of replicas is critical to HDFS reliability and performance. Optimizing replica placement distinguishes HDFS from most other distributed file systems. This is a feature that needs lots of tuning and experience. The purpose of a rack-aware replica placement policy is to improve data reliability, availability, and network bandwidth utilization. The current implementation for the replica placement policy is a first effort in this direction. The short-term goals of implementing this policy are to validate it on production systems, learn more about its behavior, and build a foundation to test and research more sophisticated policies.
>
> Large HDFS instances run on a cluster of computers that commonly spread across many racks. Communication between two nodes in different racks has to go through switches. In most cases, network bandwidth between machines in the same rack is greater than network bandwidth between machines in different racks.
>
> The NameNode determines the rack id each DataNode belongs to via the process outlined in [Hadoop Rack Awareness](https://hadoop.apache.org/docs/r3.1.3/Hadoop-project-dist/Hadoop-common/RackAwareness.html). A simple but non-optimal policy is to place replicas on unique racks. This prevents losing data when an entire rack fails and allows use of bandwidth from multiple racks when reading data. This policy evenly distributes replicas in the cluster which makes it easy to balance load on component failure. However, this policy increases the cost of writes because a write needs to transfer blocks to multiple racks.
>
> For the common case, when the replication factor is three, `HDFSâ€™s placement policy is to put one replica on the local machine if the writer is on a datanode`, otherwise on a random datanode, `another replica on a node in a different (remote) rack`, and the `last on a different node in the same remote rack`. This policy cuts the inter-rack write traffic which generally improves write performance. The chance of rack failure is far less than that of node failure; this policy does not impact data reliability and availability guarantees. However, it does reduce the aggregate network bandwidth used when reading data since a block is placed in only two unique racks rather than three. With this policy, the replicas of a file do not evenly distribute across the racks. One third of replicas are on one node, two thirds of replicas are on one rack, and the other third are evenly distributed across the remaining racks. This policy improves write performance without compromising data reliability or read performance.
>
> If the replication factor is greater than 3, the placement of the 4th and following replicas are determined randomly while keeping the number of replicas per rack below the upper limit (which is basically `(replicas - 1) / racks + 2`).
>
> Because the NameNode does not allow DataNodes to have multiple replicas of the same block, maximum number of replicas created is the total number of DataNodes at that time.
>
> After the support for [Storage Types and Storage Policies](https://hadoop.apache.org/docs/r3.1.3/Hadoop-project-dist/Hadoop-hdfs/ArchivalStorage.html) was added to HDFS, the NameNode takes the policy into account for replica placement in addition to the rack awareness described above. The NameNode chooses nodes based on rack awareness at first, then checks that the candidate node have storage required by the policy associated with the file. If the candidate node does not have the storage type, the NameNode looks for another node. If enough nodes to place replicas can not be found in the first path, the NameNode looks for nodes having fallback storage types in the second path.
>
> The current, default replica placement policy described here is a work in progress.
>
> ***
>
> #### Replica Selection
>
> To minimize global bandwidth consumption and read latency, HDFS tries to satisfy a read request from a replica that is closest to the reader. If there exists a replica on the same rack as the reader node, then that replica is preferred to satisfy the read request. If HDFS cluster spans multiple data centers, then a replica that is resident in the local data center is preferred over any remote replica.

![image-20230113134201501](Hadoop.assets/image-20230113134201501.png)

**æºç åˆ†æ**

æºä»£ç å¯ä»¥å» maven ä»“åº“æ‰¾ Hadoop-dfs çš„æºç åŒ…ï¼Œç„¶åå† `org.apache.Hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault` è¿™ä¸ªç±»çš„ `chooseTargetInOrder` æ–¹æ³•

```java
protected Node chooseTargetInOrder(int numOfReplicas, 
                                   Node writer,
                                   final Set<Node> excludedNodes,
                                   final long blocksize,
                                   final int maxNodesPerRack,
                                   final List<DatanodeStorageInfo> results,
                                   final boolean avoidStaleNodes,
                                   final boolean newBlock,
                                   EnumMap<StorageType, Integer> storageTypes)
    throws NotEnoughReplicasException {
    final int numOfResults = results.size();
    if (numOfResults == 0) {
        // ç¬¬ä¸€ä¸ªå‰¯æœ¬ï¼Œé€‰æ‹©æœ¬åœ°èŠ‚ç‚¹
        DatanodeStorageInfo storageInfo = chooseLocalStorage(
            writer,
            excludedNodes, 
            blocksize, 
            maxNodesPerRack, 
            results, 
            avoidStaleNodes,
            storageTypes, 
            true
        );

        writer =
            (storageInfo != null) ? storageInfo.getDatanodeDescriptor() : null;
        if (--numOfReplicas == 0) {
            return writer;
        }
    }
    // dn0 å°±æ˜¯åˆšåˆšé€‰æ‹©çš„ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
    final DatanodeDescriptor dn0 = results.get(0).getDatanodeDescriptor();
    if (numOfResults <= 1) {
        // ç¬¬äºŒä¸ªå‰¯æœ¬ï¼Œé€‰æ‹©å’Œ dn0 è¿œç¨‹çš„èŠ‚ç‚¹
        chooseRemoteRack(
            1, 
            dn0, 
            excludedNodes, 
            blocksize, 
            maxNodesPerRack,
            results, 
            avoidStaleNodes, 
            storageTypes
        );
        if (--numOfReplicas == 0) {
            return writer;
        }
    }
    if (numOfResults <= 2) {
        // dn1 å°±æ˜¯åˆšåˆšé€‰æ‹©çš„ç¬¬äºŒä¸ªèŠ‚ç‚¹
        final DatanodeDescriptor dn1 = results.get(1).getDatanodeDescriptor();
        // åˆ¤æ–­åˆšåˆšé€‰æ‹©çš„è¿ä¸ªæ˜¯å¦æ˜¯åŒä¸€ä¸ªæœºæ¶
        if (clusterMap.isOnSameRack(dn0, dn1)) { // å¦‚æœæ˜¯åŒä¸€ä¸ªï¼Œæœ€åä¸€ä¸ªå°†é€‰æ‹©è¿œç¨‹æœºæ¶
            chooseRemoteRack(
                1, 
                dn0, 
                excludedNodes, 
                blocksize, 
                maxNodesPerRack,
                results, 
                avoidStaleNodes, 
                storageTypes
            );
        } else if (newBlock){ // å¦‚æœä¸åœ¨åŒäºä¸€ä¸ªï¼Œå¹¶ä¸”æ˜¯æ–°å—ï¼Œé‚£å°±é€‰æ‹©å’Œ dn1 ç›¸åŒçš„æœºæ¶
            chooseLocalRack(
                dn1, 
                excludedNodes, 
                blocksize, 
                maxNodesPerRack,
                results, 
                avoidStaleNodes, 
                storageTypes
            );
        } else {
            chooseLocalRack(
                writer, 
                excludedNodes, 
                blocksize, 
                maxNodesPerRack,
                results, 
                avoidStaleNodes, 
                storageTypes
            );
        }
        if (--numOfReplicas == 0) {
            return writer;
        }
    }
    chooseRandom(numOfReplicas, NodeBase.ROOT, excludedNodes, blocksize,
                 maxNodesPerRack, results, avoidStaleNodes, storageTypes);
    return writer;
}
```

**è¯»æµç¨‹**

![image-20230113142742758](Hadoop.assets/image-20230113142742758.png)

1. é¦–å…ˆå®¢æˆ·ç«¯å‘ NameNode è¯·æ±‚æ–‡ä»¶çš„ä¸‹è½½
2. NameNode å°†éªŒè¯ä¸‹è½½çš„æ–‡ä»¶æ˜¯å¦åˆæ³•ï¼Œæƒé™æ˜¯å¦æ­£å¸¸ç­‰ä¿¡æ¯ï¼Œå¦‚æœå¯ä»¥ä¸‹è½½å°†è¿”å›ç›®æ ‡æ–‡ä»¶çš„å…ƒæ•°æ®
3. å®¢æˆ·ç«¯åˆ›å»ºè¯»æ•°æ®æµï¼Œé€‰æ‹©æœ€è¿‘çš„èŠ‚ç‚¹ï¼ˆä¹Ÿä¼šè€ƒè™‘è´Ÿè½½å‡è¡¡ï¼‰è¿›è¡Œè¯»å–
4. è¯»å–å®Œç¬¬ä¸€å—åå†è¯»é‡æ–°é€‰æ‹©èŠ‚ç‚¹è¯»å–ä¸‹ä¸€å—ï¼Œ`è¿™é‡Œæ˜¯ä¸²è¡Œè¯»å¹¶ä¸æ˜¯å¹¶è¡Œ`

#### NameNode å’Œ SecondNameNode

**NameNode æ˜¯å¦‚ä½•å­˜å‚¨æ•°æ®çš„**

å®¢æˆ·ç«¯ä¸Šä¼ çš„æ–‡ä»¶ä¼šåˆ†å—åå­˜å‚¨åœ¨ DataNode æŒ‡å®šçš„æ–‡ä»¶å¤¹ä¸­ï¼Œè¿™ä¸€ç‚¹å¾ˆå®¹æ˜“ç†è§£ï¼Œé—®é¢˜çš„å…³é”®æ˜¯è¿™äº›æ–‡ä»¶çš„å…ƒæ•°æ®æ˜¯å¦‚ä½•è¿›è¡Œå­˜å‚¨çš„å‘¢ï¼Ÿ

èƒ½å¤Ÿç”¨æ¥è¿›è¡Œæ•°æ®å­˜å‚¨çš„åªæœ‰ä¸¤ç§æ–¹å¼ï¼šä¸€ç§æ˜¯å­˜æ”¾å†å†…å­˜ä¸­ï¼Œé€Ÿåº¦å¿«ä½†æ˜¯ä¸å®‰å…¨ï¼›å¦ä¸€ç§æ˜¯å­˜æ”¾åœ¨ç£ç›˜ä¸­ï¼Œé€Ÿåº¦æ…¢ä½†æ˜¯å®‰å…¨ã€‚Hadoop è¿™ç§åœ¨çº¿çš„æ–‡ä»¶ç³»ç»Ÿå¦‚ä½•å…¼é¡¾å¿«é€Ÿçš„å®‰å…¨å‘¢ï¼Ÿé‚£å°±æ˜¯é€šè¿‡ç£ç›˜é¡ºåºè¯»å†™é€Ÿåº¦æ¯”è¾ƒå¿«çš„ç‰¹ç‚¹ï¼Œæ¯æ¬¡æ¥æ–°çš„æ–‡ä»¶æ—¶ï¼Œåªå˜æ›´å†…å­˜ä¸­çš„æ•°æ®å¹¶ä¸”å°†æ–‡ä»¶çš„å˜æ›´è®°å½•åœ¨ editors æ–‡ä»¶ä¸­ï¼ŒæœåŠ¡å™¨å…³æœºçš„æ—¶å€™å†è¿›è¡Œç»Ÿä¸€çš„åˆå¹¶ã€‚è¿™æ ·å°±å¯ä»¥å³å¿«åˆå®‰å…¨ã€‚

å…ƒæ•°æ®ä¼šå‚¨å­˜åœ¨ NameNode ä¸­ï¼Œä¸»è¦åˆ†ä¸ºä¸‰ä¸ªæ–‡ä»¶ fsimageã€editors å’Œ edits\_inprogress ä¸­è¿›è¡Œä¿å­˜ï¼Œå…¶ä¸­ fsimage æ˜¯æ€»çš„å…ƒæ•°æ®ï¼Œeditors æ˜¯è¿˜æ²¡æœ‰æ¥å¾—åŠè¿›è¡Œåˆå¹¶çš„æ•°æ®ï¼Œedits\_inprogress æ˜¯å½“å‰æ­£åœ¨ä½¿ç”¨çš„è®°å½•æ–‡ä»¶ã€‚NameNode å’Œ SeconNameNode çš„å…³ç³»å¯ä»¥åšä¸€ä¸ªæ¯”å–»ï¼šæ¯”å¦‚ä½ ä¸Šè¯¾å¬è®²éœ€è¦è®°ç¬”è®°ï¼Œä½ æœ‰ä¸€ä¸ªç¬”è®°æœ¬ï¼ˆfsimageï¼‰ã€ä¸€äº›æ¼”ç®—çº¸ï¼ˆeditorsã€ edits\_inprogressï¼‰å’Œä¸€ä¸ªåŒæ¡Œï¼ˆSeconNameNode ï¼‰ï¼Œç°åœ¨è€å¸ˆå°±æ˜¯å®¢æˆ·ç«¯ï¼Œä»–ä¸åœçš„å‘ä½ æäº¤çŸ¥è¯†ï¼Œä½†æ˜¯å¦‚æœä½ ä¸€ç›´ä¿®æ”¹ä½ ç¬”è®°æœ¬ä¸Šçš„å†…å®¹å°±ä¼šå¾ˆæ…¢ï¼Œè·Ÿä¸ä¸Šè€å¸ˆçš„èŠ‚å¥ï¼Œè¿™ä¸ªæ—¶å€™ä½ å¯ä»¥å…ˆç†è§£çŸ¥è¯†æ”¾åœ¨è„‘å­é‡Œï¼ˆæ›´æ–°å†…å­˜ï¼‰ï¼ŒåŒæ—¶å°†è€å¸ˆè®²çš„å†…å®¹é¡ºåºçš„è®°å½•åœ¨æ¼”ç®—çº¸ä¸Šï¼ˆé¡ºåºå†™å…¥åˆ° editors ä¸­ï¼‰ï¼Œç„¶åç­‰è¯¾ä¸‹å†æ•´ç†åˆ°ç¬”è®°æœ¬ä¸Šï¼ˆæœåŠ¡å™¨å…³é—­æ—¶ååˆå¹¶ï¼‰ï¼Œä½†æ˜¯å¦‚æœä¸Šè¯¾è®²çš„å†…å®¹å¾ˆå¤šä½ å°±è¦æ•´ç†å¾ˆé•¿æ—¶é—´ï¼Œè¿™ä¸ªæ—¶å€™ä½ çš„å¥½åŒæ¡Œå°±ä¸Šåœºäº†ï¼Œä»–ä¼šæ¯éš”ä¸€æ®µæ—¶é—´å°±å°†ä½ çš„ç¬”è®°æœ¬å’Œæ¼”ç®—çº¸æ‹¿èµ°å¸®ä½ æ•´ç†å¥½å†é€å›æ¥ï¼ˆå°† fsimge å’Œ editors å–èµ°è¿›è¡Œåˆå¹¶ï¼Œè¿™ä¸ªæ—¶å€™ä½ çš„æ¼”ç®—çº¸æ˜¯ edits\_inprogress ï¼‰ï¼Œè¿™æ ·ä½ å°±å¯ä»¥å¾ˆè½»æ¾äº†ã€‚å…·ä½“çš„æµç¨‹å¦‚ä¸‹ï¼š

![image-20230113144812150](Hadoop.assets/image-20230113144812150.png)

**æŸ¥çœ‹ fsimageã€editors**

fsimgeã€editors é€šè¿‡æ­£å¸¸çš„æ‰‹æ®µæ˜¯æ‰“ä¸å¼€çš„ï¼Œå¯ä»¥é€šè¿‡ oivã€oev å‘½ä»¤æ¥è½¬æˆ XML æ ¼å¼è¿›è¡ŒæŸ¥çœ‹ï¼Œå…·ä½“çš„å‘½ä»¤å¦‚ä¸‹ï¼š

```shell
# oiv/oev -p æ–‡ä»¶ç±»å‹ -i fsimage/editorsæ–‡ä»¶å -o è¾“å‡ºè·¯å¾„
```

**æ£€æŸ¥ç‚¹è®¾ç½®**

2NN ä¼šæ¯éš”ä¸€æ®µæ—¶é—´å°±è¯¢é—® NN æ˜¯å¦éœ€è¦è¿›è¡Œåˆå¹¶ï¼Œè¯¢é—®çš„é—´éš”æ—¶é—´å’Œåˆå¹¶çš„åˆå¹¶çš„æ–‡ä»¶æ•°é‡å¯ä»¥é€šè¿‡ `hdfs-site.xml` è¿›è¡Œé…ç½®ï¼Œå…·ä½“çš„é…ç½®ä»£ç å¦‚ä¸‹ï¼š

```xml
<property>
    <!--åªæœ‰å½“æ–‡ä»¶ editors ä¸­çš„æ–‡ä»¶åˆ°è¾¾æŒ‡å®šæ•°é‡æ—¶æ‰è¿›è¡Œåˆå¹¶ï¼Œé»˜è®¤é»˜è®¤ 1000000-->
	<name>dfs.namenode.checkpoint.period</name>
    <value>1000000</value>
</property>
<property>
    <!--é»˜è®¤ 2NN ä¸€åˆ†é’Ÿå‘ NN è¯¢é—®ä¸€æ¬¡-->
	<name>dfs.namenode.checkpoint.check.period</name>
    <value>60s</value>
</property>
```

2NN è¿™ç§æ–¹å¼åŸºæœ¬ä¸ç”¨ï¼Œä¸€èˆ¬éƒ½æ˜¯é…ç½® NN çš„é«˜å¯ç”¨ã€‚

#### DataNode å·¥ä½œæœºåˆ¶

![image-20230113165452919](Hadoop.assets/image-20230113165452919.png)

ä¸Šè¿°çš„æ—¶é—´å¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶è¿›è¡Œé…ç½®ï¼Œè¿™é‡Œå°±ä¸æ¼”ç¤ºäº†ã€‚åœ¨ dataNode å†…éƒ¨ä¼šä½¿ç”¨ crc32 ç®—æ³•å¯¹æ–‡ä»¶è¿›è¡Œæ ¡éªŒï¼Œæ¥ä¿è¯æ•°æ®çš„å‡†ç¡®æ€§ã€‚

### MapReduce

#### MapReduce æ¦‚è¿°

**å®šä¹‰**

MapReduce æ˜¯ Google æå‡ºçš„ä¸€ä¸ªè½¯ä»¶æ¶æ„ï¼Œç”¨äºå¤§è§„æ¨¡æ•°æ®é›†çš„å¹¶è¡Œè¿ç®—ã€‚æ¦‚å¿µ Map å’Œ Reduce ï¼ŒåŠä»–ä»¬çš„ä¸»è¦æ€æƒ³ï¼Œéƒ½æ˜¯ä»å‡½æ•°å¼ç¼–ç¨‹è¯­è¨€å€Ÿé‰´çš„ï¼Œè¿˜æœ‰ä»çŸ¢é‡ç¼–ç¨‹è¯­è¨€å€Ÿæ¥çš„ç‰¹æ€§ã€‚

å½“å‰çš„è½¯ä»¶å®ç°æ˜¯æŒ‡å®šä¸€ä¸ª Map å‡½æ•°ï¼Œç”¨æ¥æŠŠä¸€ç»„é”®å€¼å¯¹æ˜ å°„æˆä¸€ç»„æ–°çš„é”®å€¼å¯¹ï¼ŒæŒ‡å®šå¹¶å‘çš„ Reduce å‡½æ•°ï¼Œç”¨æ¥ä¿è¯æ‰€æœ‰æ˜ å°„çš„é”®å€¼å¯¹ä¸­çš„æ¯ä¸€ä¸ªå…±äº«ç›¸åŒçš„é”®ç»„ã€‚

**ä¼˜åŠ¿ã€åŠ£åŠ¿**

ä¼˜ç‚¹

> * æ˜“äºç¼–ç¨‹ï¼Œç”¨æˆ·åªå…³å¿ƒä¸šåŠ¡é€»è¾‘ï¼Œå®ç°æ¡†æ¶æ¥å£
> * è‰¯å¥½çš„æ‰©å±•æ€§ï¼šå¯ä»¥åŠ¨æ€å¢åŠ æœåŠ¡å™¨ï¼Œè§£å†³è®¡ç®—èµ„æºä¸å¤Ÿçš„é—®é¢˜
> * é«˜å®¹é”™æ€§ï¼šä»»ä½•ä¸€å°æŒ‚æ‰å¯ä»¥å°†ä»»åŠ¡è½¬ç§»åˆ°å…¶ä»–èŠ‚ç‚¹
> * é€‚åˆæµ·é‡æ•°æ®è®¡ç®—ï¼ˆTB/PBï¼‰ï¼Œå‡ åƒå°æœåŠ¡å™¨å…±åŒè®¡ç®—

ç¼ºç‚¹

> * ä¸æ“…é•¿è¯•è¯•è®¡ç®—ï¼Œä¸èƒ½è¾¾åˆ°æ¯«ç§’çº§åˆ«
> * ä¸æ“…é•¿æµå¼è®¡ç®— ï¼ŒSparkstreamingã€Flink
> * ä¸æ“…é•¿DAGæœ‰å‘æ— å…³ç¯å›¾è®¡ç®—ï¼ˆå¹¶éä¸è¡Œï¼‰ã€‚Spark æ“…é•¿

#### WordCount æ¡ˆä¾‹

**MapReduce ç¼–ç¨‹è§„èŒƒ**

ä¸€èˆ¬çš„ MapReduce ç¨‹åºç”± Mapperï¼ŒReducerï¼ŒDriver ç»„æˆï¼Œä½†æ˜¯æœ‰çš„ç¨‹åºä¹Ÿå¯èƒ½æ²¡æœ‰ Reducerã€‚å¯¹äºä¸€ä¸ªä»»åŠ¡é¦–å…ˆä¼šåˆ†é…ç»™å¤šä¸ªæœåŠ¡å™¨ï¼ˆå°çš„è¯ä¹Ÿå¯èƒ½æ˜¯ä¸€ä¸ªï¼‰ï¼Œæ¯ä¸ªæœåŠ¡å™¨æ¥æ‰§è¡Œ Mapper ç¨‹åºï¼Œç„¶åå°†æ‰§è¡Œåçš„ç»“æœäº¤ç»™ Reducer ç¨‹åºæ¥è¿›è¡Œæ±‡æ€»ã€‚

![image-20230124155003773](Hadoop.assets/image-20230124155003773.png)

WordCount çš„å¤§è‡´æµç¨‹å¦‚ä¸‹ï¼š

![image-20230124161017289](Hadoop.assets/image-20230124161017289.png)

**Mapper**

é€šè¿‡ç»§æ‰¿ `org.apache.Hadoop.mapreduce.Mapper` æ¥å®ç°è‡ªå·±çš„ç¨‹åºï¼ˆåœ¨ç¼–å†™ä»£ç æ—¶ï¼Œä¸€å®šè¦`æ³¨æ„å¯¼åŒ…`ï¼‰ï¼Œé¦–å…ˆçœ‹ä¸€ä¸‹ Mapper ç±»çš„å„ä¸ªæ–¹æ³•åŠå®˜æ–¹çš„è¯´æ˜ï¼š

```java
public class Mapper<KEYIN, VALUEIN, KEYOUT, VALUEOUT> {

    /**
   * The <code>Context</code> passed on to the {@link Mapper} implementations.
   */
    public abstract class Context
        implements MapContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> {
    }

    /**
   * Called once at the beginning of the task.
   */
    protected void setup(Context context
                        ) throws IOException, InterruptedException {
        // NOTHING
    }

    /**
   * Called once for each key/value pair in the input split. Most applications
   * should override this, but the default is the identity function.
   */
    protected void map(KEYIN key, VALUEIN value, 
                       Context context) throws IOException, InterruptedException {
        context.write((KEYOUT) key, (VALUEOUT) value);
    }

    /**
   * Called once at the end of the task.
   */
    protected void cleanup(Context context
                          ) throws IOException, InterruptedException {
        // NOTHING
    }

    /**
   * Expert users can override this method for more complete control over the
   * execution of the Mapper.
   * @param context
   * @throws IOException
   */
    public void run(Context context) throws IOException, InterruptedException {
        setup(context);
        try {
            while (context.nextKeyValue()) {
                map(context.getCurrentKey(), context.getCurrentValue(), context);
            }
        } finally {
            cleanup(context);
        }
    }
}
```

`org.apache.Hadoop.mapreduce.Mapper` å£°æ˜äº†ä¸€ä¸ª Mapper å¯èƒ½ç”¨åˆ°çš„å‡ ä¸ªæ–¹æ³•ï¼Œå€¼å¾—æ³¨æ„çš„æ˜¯ `map` æ–¹æ³•ï¼Œä»–ä¼šå¯¹æ¯ä¸€ä¸ª **Key/Value** éƒ½æ‰§è¡Œä¸€æ¬¡ã€‚åœ¨æˆ‘ä»¬çš„ç¤ºä¾‹ä¸­ï¼Œä¼šå°†æ¯ä¸€è¡Œçš„æ–‡æœ¬éƒ½æ‰§è¡Œä¸€æ¬¡ map æ–¹æ³•ã€‚WordCount ç¨‹åºçš„ Mapper ç±»å¦‚ä¸‹ï¼š

```java
package top.cafebabe202.study.Hadoop.mapreduce;

import org.apache.Hadoop.io.IntWritable;
import org.apache.Hadoop.io.LongWritable;
import org.apache.Hadoop.io.Text;
import org.apache.Hadoop.mapreduce.Mapper;

import java.io.IOException;

// ç»§æ‰¿ Mapper ç±»å‹ã€‚å››ä¸ªæ³›å‹ï¼Œæ˜¯è¾“å…¥è¾“å‡ºçš„ KV ç±»å‹
public class WordCountMapper extends Mapper<LongWritable, Text, Text, IntWritable> {

    // åˆ›å»ºä¸¤ä¸ªå˜é‡ï¼Œç”¨äºå°†æœ¬ map çš„ä¿¡æ¯è¾“å‡ºï¼Œå†™æˆå…¬å…±å˜é‡å¯ä»¥å‡å°‘å¯¹è±¡çš„åˆ›å»ºï¼Œæé«˜æ€§èƒ½
    // å› ä¸ºæ¯æ¬¡å†™å‡ºçš„æ—¶å€™éƒ½æ˜¯å°†å¯¹è±¡è¿›è¡Œåºåˆ—åŒ–ï¼Œå†™å‡ºä¹‹åå¹¶ä¸ä¼šä¾èµ–åŸå¯¹è±¡ï¼Œæ‰€ä»¥å¯ä»¥ä½¿ç”¨åŒä¸€ä¸ªå¯¹è±¡
    private final Text outK = new Text();
    private final IntWritable outV = new IntWritable(1);

    /**
     * @param key     åœ¨æ•°æ®å—ä¸­çš„å­—èŠ‚åç§»é‡
     * @param value   è¯¥ Map çš„è¾“å…¥å€¼ï¼Œæˆ‘è§‰å¾—åº”è¯¥ä¹Ÿå¯ä»¥æ˜¯äºŒè¿›åˆ¶æµå§ï¼Œä¸èƒ½åªèƒ½å¤„ç†æ–‡æœ¬æ•°æ®å§ï¼Œæˆ‘è§‰å¾—è¿™ä¸ª value æ¯æ¬¡çš„å€¼åº”è¯¥æŒ‰ç…§ç±»å‹è¿›è¡Œåˆ†å‰²å§ï¼ŒText ç±»å‹æ˜¯æŒ‰ç…§è¡Œåˆ’åˆ†çš„ï¼Œä¸çŸ¥é“äºŒè¿›åˆ¶æ•°æ®åˆ†æ€ä¹ˆåˆ’åˆ†
     * @param context ä¸Šä¸‹æ–‡å¯¹è±¡ï¼Œç”¨äºå‘ reduce ä¼ è¾“æ•°æ®ï¼Œä¹ŸåŒ…å«è¯¥ä»»åŠ¡ç›¸å…³çš„é…ç½®ä¿¡æ¯
     */
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {

        // è¿™é‡Œæ¯æ¬¡éƒ½æ˜¯ä¼ é€’è¿‡æ¥ä¸€è¡Œæ–‡æœ¬ä¿¡æ¯ï¼Œæ‰€ä»¥è¦å°†ä¸€è¡Œæ–‡æœ¬æ‹†åˆ†æˆå¤šä¸ªå•è¯
        String[] words = value.toString().split(" ");
        for (String word : words) {
            this.outK.set(word);

            // æ¯ä¸€ä¸ªå•è¯éƒ½æ˜¯ç¬¬ä¸€æ¬¡å‡ºç°ï¼Œæ‰€ä»¥æ¯ä¸ªå•è¯æ¬¡æ•°éƒ½æ˜¯ 1ï¼Œç›¸åŒçš„å•è¯ä¼šæœ‰å¤šä¸ª key/value å¯¹
            context.write(outK, outV);
        }
    }
}
```

**Reducer**

é¦–å…ˆè¿˜æ˜¯å…ˆçœ‹ä¸€ä¸‹å®˜æ–¹çš„ `org.apache.Hadoop.mapreduce.Reducer` ç±»ï¼š

```java
package org.apache.Hadoop.mapreduce;

public class Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> {

  /**
   * The <code>Context</code> passed on to the {@link Reducer} implementations.
   */
  public abstract class Context 
    implements ReduceContext<KEYIN,VALUEIN,KEYOUT,VALUEOUT> {
  }

  /**
   * Called once at the start of the task.
   */
  protected void setup(Context context
                       ) throws IOException, InterruptedException {
    // NOTHING
  }

  /**
   * This method is called once for each key. Most applications will define
   * their reduce class by overriding this method. The default implementation
   * is an identity function.
   */
  protected void reduce(KEYIN key, Iterable<VALUEIN> values, Context context
                        ) throws IOException, InterruptedException {
    for(VALUEIN value: values) {
      context.write((KEYOUT) key, (VALUEOUT) value);
    }
  }

  /**
   * Called once at the end of the task.
   */
  protected void cleanup(Context context
                         ) throws IOException, InterruptedException {
    // NOTHING
  }

  /**
   * Advanced application writers can use the 
   * {@link #run(org.apache.Hadoop.mapreduce.Reducer.Context)} method to
   * control how the reduce task works.
   */
  public void run(Context context) throws IOException, InterruptedException {
    setup(context);
    try {
      while (context.nextKey()) {
        reduce(context.getCurrentKey(), context.getValues(), context);
        // If a back up store is used, reset it
        Iterator<VALUEIN> iter = context.getValues().iterator();
        if(iter instanceof ReduceContext.ValueIterator) {
          ((ReduceContext.ValueIterator<VALUEIN>)iter).resetBackupStore();        
        }
      }
    } finally {
      cleanup(context);
    }
  }
}
```

åŒæ ·å€¼å¾—æ³¨æ„çš„æ˜¯ `reduce` æ–¹æ³•ï¼Œä»–ä¼šå¯¹æ¯ä¸€ä¸ª **Key** æ‰§è¡Œä¸€æ¬¡è¯¥æ–¹æ³•ï¼Œåœ¨æˆ‘ä»¬çš„ç¤ºä¾‹å½“ä¸­ï¼ŒMapper æ–¹æ³•çš„è¾“å‡ºç±»å‹æ˜¯ Text/IntWriteableï¼Œå…¶ä¸­ Key ä¸ºå•è¯ï¼Œåœ¨MapperRecuer æ‰§è¡Œè¿‡ç¨‹ä¸­ä¼šå°†æ‰€ä»¥çš„ Key è¿›è¡Œåˆå¹¶ä½œä¸º Reducer çš„è¾“å…¥ Keyï¼Œå°†ä»–ä»¬çš„ Value ç»„æˆä¸€ä¸ªé›†åˆä½œä¸º Reducer çš„è¾“å…¥ Valueã€‚WordCount çš„ Reducer ç±»å¦‚ä¸‹ï¼š

```java
// å››ä¸ªå‚æ•°ï¼Œåˆ†åˆ«æ˜¯è¾“å…¥è¾“å‡ºçš„ KV ç±»å‹ï¼Œåº”è¯¥å’Œ Mapper çš„è¾“å‡º KV ç±»å‹ä¸€æ ·ã€‚
public class WordCountReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    private final IntWritable outV = new IntWritable();

    /**
     * @param text    Mapper è¾“å‡ºçš„ Keyï¼Œæ¯ä¸ª Key åªä¼ å…¥ä¸€æ¬¡
     * @param values  Mapper è¾“å‡ºä¸­æ¯ä¸ª Key çš„æ‰€æœ‰ value å€¼çš„é›†åˆ
     * @param context ä¸Šä¸‹æ–‡å¯¹è±¡ï¼Œç”¨äºå‘ reduce ä¼ è¾“æ•°æ®ï¼Œä¹ŸåŒ…å«è¯¥ä»»åŠ¡ç›¸å…³çš„é…ç½®ä¿¡æ¯
     */
    @Override
    public void reduce(Text text, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
        int sum = 0;
        for (IntWritable value : values) {
            sum += value.get();
        }
        this.outV.set(sum);
        context.write(text, outV);
    }
}
```

**Driver**

```java
// ä»»åŠ¡çš„æ€»æµç¨‹ï¼Œéƒ½å·®ä¸å¤šå§ï¼Œå…«è‚¡
public class WorkCountDriver {
    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException {
        
        // åˆ›å»º job å¯¹è±¡
        Configuration configuration = new Configuration();
        Job job = Job.getInstance(configuration);

        // è®¾ç½®å¯åŠ¨ç±»
        job.setJarByClass(WorkCountDriver.class);

        // è®¾ç½® map å’Œ reduce ç±»
        job.setMapperClass(WordCountMapper.class);
        job.setReducerClass(WordCountReducer.class);

        // è®¾ç½® map å’Œæœ€ç»ˆçš„ K,V è¾“å‡ºç±»å‹
        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(IntWritable.class);
        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        // è®¾ç½®è¾“å‡ºè¾“å‡ºè·¯å¾„
        FileInputFormat.setInputPaths(job, new Path("D:\\wordcount"));
        FileOutputFormat.setOutputPath(job, new Path("D:\\wordcountres"));

        //æäº¤ä»»åŠ¡
        boolean b = job.waitForCompletion(true);
        System.out.println(b ?"Successful":"fail");
        System.exit(b ? 0 : 1);
    }
}
```

**æ‰§è¡Œ**

é¦–å…ˆåˆ›å»ºä¸€ä¸ªè¾“å…¥ç›®å½•ï¼Œç„¶åè®¾ç½®è¾“å‡ºç›®å½•ï¼ˆå’Œæ‰§è¡Œå®˜æ–¹ WordCount ç¨‹åºä¸€æ ·ï¼‰ï¼Œç„¶åç‚¹å‡»è¿è¡ŒæŒ‰é’®ã€‚è¿è¡Œç»“æœå’Œæ‰§è¡Œå®˜æ–¹ç»“æœä¸€æ ·ï¼Œè¿™é‡Œä¸è¿‡å¤šè¿›è¡Œè®²è§£ã€‚

#### åºåˆ—åŒ–

**ä¸ºä»€ä¹ˆä¸ç”¨ Java åºåˆ—åŒ–**

å¦‚æœæƒ³è¦ä¼ è¾“æˆ–å­˜å‚¨ Java å¯¹è±¡ï¼Œå¯ä»¥é€šè¿‡å®ç° Java çš„ Serializable æ¥å£æ¥å®ç°åºåˆ—åŒ–ï¼Œæ—¢ç„¶ Java æœ¬èº«å°±å¯ä»¥å®ç°åºåˆ—åŒ–ï¼Œé‚£ä¹ˆä¸ºä»€ä¹ˆ Hadoop è¿˜è¦å®ç°è‡ªå·±çš„åºåˆ—åŒ–æ–¹æ³•å‘¢ï¼Ÿ

Java åœ¨åºåˆ—åŒ–å¯¹è±¡æ—¶é™¤äº†å¯¹è±¡çš„æ•°æ®ä¿¡æ¯æ—¶è¿˜ä¼šæ·»åŠ è®¸å¤šé¢å¤–çš„ä¿¡æ¯ï¼Œä¾‹å¦‚ï¼šæ ¡éªŒç ã€å¤´ä¿¡æ¯ã€ç±»çš„ç»§æ‰¿å…³ç³»ç­‰ä¸€äº›åˆ—å†…å®¹ï¼Œè¿™äº›ä¿¡æ¯è€ƒè™‘äº†ä¼—å¤šå› ç´ ã€‚ä½†æ˜¯ Hadoop çš„åºåˆ—åŒ–åªæ˜¯ç”¨æ¥åœ¨ç³»ç»Ÿå†…éƒ¨è¿›è¡Œä¼ è¾“ï¼Œç¯å¢ƒç›¸å¯¹å®‰å…¨ï¼Œå¹¶ä¸éœ€è¦è¿‡å¤šçš„ä¿¡æ¯æ¥ä¿éšœå®‰å…¨ï¼Œæ‰€ä»¥å¯¹äº Hadoop æ¥è¯´ Java è‡ªå¸¦çš„åºåˆ—åŒ–æ¡†æ¶è¿‡é‡äº†ï¼Œéœ€è¦è‡ªå·±åˆ›å»ºä¸€ä¸ªè½»é‡åŒ–çš„åºåˆ—åŒ–ä½“ç³»ã€‚

**å¦‚ä½•å®ç°åºåˆ—åŒ–**

æƒ³è¦åœ¨ Hadoop ä¸­å®ç°åºåˆ—åŒ–ï¼Œåªéœ€è¦å®ç° `org.apache.hadoop.io.Writable` æ¥å£å³å¯ï¼Œå…·ä½“çš„è¦æ±‚è¯·çœ‹åè¾¹çš„ä»£ç ä¸­çš„æ³¨é‡Šã€‚

**ç¤ºä¾‹**

ä¸‹è¾¹æ˜¯æ‰‹æœºç”¨æˆ·çš„ä¸Šç½‘ä¿¡æ¯ï¼ˆéšä¾¿å†™çš„ï¼‰ï¼Œæ¯ä¸€åˆ—çš„å«ä¹‰å·²ç»ç»™å®šï¼Œä½¿ç”¨  è¿›è¡Œåˆ†å‰²ï¼Œç½‘å€åˆ—å¯èƒ½ä¼šç¼ºä¹éƒ¨åˆ†ä¿¡æ¯ï¼Œç°åœ¨è¦æ±‚æŒ‰ç…§æ‰‹æœºå·è¿›è¡Œæ±‡æ€»ï¼Œè¾“å‡ºæ–‡ä»¶ä¸­å°†åŒ…å« 4 åˆ—ï¼Œåˆ†åˆ«æ˜¯ï¼šæ‰‹æœºå·ã€ä¸Šè¡Œæµé‡æ€»å’Œã€ä¸‹è¡Œæµé‡æ€»å’Œã€æµé‡æ€»å’Œã€‚

```
åºå·	æ‰‹æœºå·		IP			ç½‘å€				ä¸Šè¡Œæµé‡	ä¸‹è¡Œæµé‡	çŠ¶æ€ç 
1	15123772126	192.168.1.1	www.baidu.com	191			1230		200
1	15123772122	192.168.1.2					191			1230		200
1	15123772126	192.168.1.1	www.baidu.com	191			1230		200
1	15123772122	192.168.1.2	www.google.com	191			1230		200
1	15123772126	192.168.1.1					191			1230		200
1	15123772126	192.168.1.1	www.baidu.com	191			1230		200
1	15123772126	192.168.1.1	www.baidu.com	191			1230		200
1	15123772122	192.168.1.2	www.baidu.com	191			1230		200
1	15123772126	192.168.1.1	www.baidu.com	191			1230		200
1	15123772126	192.168.1.1	www.baidu.com	191			1230		200
1	15123772126	192.168.1.1					191			1230		200
1	15123772122	192.168.1.2	www.baidu.com	191			1230		200
1	15123772126	192.168.1.1	www.baidu.com	191			1230		200
1	15123772126	192.168.1.1	www.baidu.com	191			1230		200
1	15123772126	192.168.1.1					191			1230		200
1	15123772126	192.168.1.1	www.baidu.com	191			1230		200
```

æ€è·¯ï¼šå…¶å®å¾ˆç®€å•ï¼Œå³å°† wordCount çš„ value ç±»å‹æ¢æˆè‡ªå®šä¹‰çš„ FlowBean ç±»å‹å³å¯ã€‚ä»¥ä¸‹æ˜¯ä»£ç ç¤ºä¾‹ã€‚

è‡ªå®šä¹‰çš„ FlowBeanï¼š

```java
/**
 * åˆ›å»ºä¸€ä¸ª FlowBean ç±»ï¼Œç”¨æ¥å­˜å‚¨æ¯ä¸ªæ‰‹æœºå·çš„ä¿¡æ¯ã€‚
 */
public class FlowBean implements Writable {

    // å®šä¹‰ç›¸å…³çš„å±æ€§ï¼Œåˆ†åˆ«ç”¨æ¥å­˜å‚¨ä¸Šè¡Œæ€»å’Œã€ä¸‹è¡Œæ€»å’Œ
    private int upSum;
    private int downSum;

    // å¿…é¡»è¦æœ‰ä¸€ä¸ªç©ºå‚æ„é€ å™¨
    public FlowBean() {
    }
    
    // è¿™é‡Œçœç•¥äº† Geter and Setter

    @Override
    public void write(DataOutput out) throws IOException {

        // å†™å‡ºå„ä¸ªéœ€è¦è¿›è¡Œåºåˆ—åŒ–çš„å±æ€§ï¼Œè¿™é‡Œçš„é¡ºåºå¯ä»¥éšæ„ï¼›å†™å‡º int ç±»å‹ä½¿ç”¨ writeInt æ–¹æ³•
        out.writeInt(this.upSum);
        out.writeInt(this.downSum);
    }

    @Override
    public void readFields(DataInput in) throws IOException {

        // è¯»å–ä¸€ä¸ªæ•´å½¢ï¼›æ³¨æ„è¿™é‡Œçš„é¡ºåºï¼Œè¦å’Œä¸Šè¾¹å†™å‡ºçš„é¡ºåºç›¸åŒï¼Œå…ˆå†™å…ˆè¯»
        this.upSum = in.readInt();
        this.downSum = in.readInt();
    }

    @Override
    public String toString() {

        // åœ¨è¾“å‡ºåˆ°æ–‡ä»¶çš„æ—¶å€™å°†è°ƒç”¨ toString æ–¹æ³•ï¼Œæ€»å’Œæ˜¯åœ¨è¿™é‡Œè¿›è¡Œè®¡ç®—çš„
        return this.upSum + "\t" + this.downSum + "\t" + (this.upSum + this.downSum);
    }
}
```

Mapper ç±»ï¼š

```java

public class MyMapper extends Mapper<LongWritable, Text, Text, FlowBean> {

    // ä¾æ—§æ˜¯å®šä¹‰å˜é‡ï¼Œç”¨æ¥å†™å‡ºæ•°æ®
    private final FlowBean bean;
    private final Text key;

    public MyMapper() {
        this.bean = new FlowBean();
        this.key = new Text();
    }

    // è¿™é‡Œå’Œ wordCount ååˆ†ç›¸ä¼¼ï¼Œå°±æ˜¯å°† value çš„ IntWrite ç±»å‹æ¢æˆäº†è‡ªå·±ç¼–å†™çš„ FlowBean
    @Override
    protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, FlowBean>.Context context) throws IOException, InterruptedException {
        String[] strs = value.toString().split("\t");
        this.key.set(strs[1]);
        this.bean.setUpSum(Integer.parseInt(strs[strs.length - 3]));
        this.bean.setDownSum(Integer.parseInt(strs[strs.length - 2]));
        context.write(this.key, this.bean);
    }
}
```

Reducer ç±»ï¼š

```java
public class MyReducer extends Reducer<Text, FlowBean, Text, FlowBean> {
    private final FlowBean bean;

    public MyReducer() {
        this.bean = new FlowBean();
    }

    // è¿™é‡Œçš„ key value å’Œ wordCount ååˆ†ç›¸ä¼¼
    @Override
    protected void reduce(Text key, Iterable<FlowBean> values, Reducer<Text, FlowBean, Text, FlowBean>.Context context) throws IOException, InterruptedException {
        int downSum = 0, upSum = 0;

        // å°†æ‰€æœ‰çš„ä¸Šä¸‹è¡Œæµé‡éƒ½åŠ åœ¨ä¸€èµ·
        for (FlowBean value : values) {
            upSum += value.getUpSum();
            downSum += value.getDownSum();
        }
        this.bean.setUpSum(upSum);
        this.bean.setDownSum(downSum);
        context.write(key, this.bean);
    }
}
```

ä¸Šè¾¹æ˜¯ä¸»è¦ä»£ç ï¼Œçœç•¥äº†åŒ…ä¿¡æ¯å’Œ Driver ä»£ç ï¼ˆå› ä¸ºå‡ ä¹ä¸€æ ·ï¼‰ã€‚æ‰§è¡Œç»“æœå¦‚ä¸‹ï¼š

```
15123772122	764		4920	5684
15123772126	2292	14760	17052
```

#### MapReduce æ ¸å¿ƒæ¡†æ¶åŸç†

![image-20230128142153788](Hadoop.assets/image-20230128142153788.png)

MapReduce çš„å·¥ä½œæµç¨‹æ¡†æ¶å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œè¦å¤„ç†çš„æ•°æ®é¦–å…ˆç»è¿‡ InputFormat è¿›è¡Œåˆ‡ç‰‡å¤„ç†ï¼Œç„¶åå°†æ¯ä¸ªåˆ‡ç‰‡äº¤ç»™ Mapper è¿›è¡Œå¤„ç†ï¼ŒMapper å¤„ç†ç»“æŸåç»è¿‡ Shuffle åå†äº¤ç»™ Recuderï¼Œæœ€åç»è¿‡ OutFormat è¾“å‡ºã€‚æ›´åŠ å…·ä½“çš„æµç¨‹å›¾å¦‚ä¸‹ï¼š

![image-20230131135717685](Hadoop.assets/image-20230131135717685.png)

1. é¦–å…ˆéœ€è¦è¾“å…¥æ–‡ä»¶
2. å®¢æˆ·ç«¯å¯¹è¾“å…¥æ•°æ®è¿›è¡Œé€»è¾‘åˆ‡ç‰‡
3. å°†åˆ‡ç‰‡ä¿¡æ¯ï¼Œç¨‹åºçš„ jar æ–‡ä»¶ï¼ŒJob çš„é…ç½®æ–‡ä»¶æ”¾ç½®åˆ°ç¼“å†²æ–‡ä»¶å¤¹ï¼Œæäº¤ä»»åŠ¡
4. å¼€å¯ MapTaskï¼ŒMapTask **æ‹‰å–**æ•°æ®
5. é€šè¿‡ InputFormat å¯¹æ•°æ®è¿›è¡Œç‰©ç†åˆ‡ç‰‡ï¼Œå½¢æˆ K,V è°ƒç”¨ Mapper çš„ map æ–¹æ³•
6. è‡ªå®šä¹‰çš„ map æ–¹æ³•æ‰§è¡Œå¯¹æ•°æ®è¿›è¡Œå¤„ç†ï¼Œç„¶åé€šè¿‡ `Context.Write(K,V)` æ–¹æ³•å†™å‡ºæ•°æ®
7. å†™å‡ºçš„æ•°æ®å°†è¢«æ”¾åˆ°ç¼“ç¯å½¢ç¼“å†²åŒº
8. å½“ç¯å½¢ç¼“å†²åŒºè¢«å ç”¨ 80% æ—¶å°†å¯¹æ•°æ®è¿›è¡Œåˆ†åŒºï¼Œå¹¶é€šè¿‡**å¿«é€Ÿæ’åº**å¯¹åˆ†åŒºå†…çš„æ•°æ®æŒ‰ç…§ key çš„ç´¢å¼•è¿›è¡Œæ’åº
9. å¯¹æ’åºå®Œçš„æ•°æ®è¿›è¡Œæº¢å†™æ“ä½œï¼Œå°†æ–‡ä»¶ä¿å­˜åˆ°ç£ç›˜
10. åœ¨ä¸€æ¬¡ä»»åŠ¡æ‰§è¡Œè¿‡ç¨‹ä¸­å¯èƒ½äº§ç”Ÿå¤šä¸ªæº¢å†™æ–‡ä»¶ï¼Œåœ¨æ‰€æœ‰ Mapper æ‰§è¡Œç»“æŸåå°†å¯¹æ‰€æœ‰åˆ†åŒºçš„å„ä¸ªæº¢å†™æ–‡ä»¶è¿›è¡Œ**å½’å¹¶æ’åº**
11. åœ¨å½’å¹¶ç»“æŸåï¼Œ**å¯ä»¥**æå‰æœºå‹åˆå¹¶æ“ä½œï¼Œæ¥æé«˜ä¼ è¾“æ•ˆç‡ï¼Œä¹Ÿå¯ä»¥ä¸è¿›è¡Œ

![image-20230131140247346](Hadoop.assets/image-20230131140247346.png)

12. å¯åŠ¨ MapTask ä»»åŠ¡ï¼Œå¹¶å‘ŠçŸ¥ ReduceTask å¤„ç†æ•°æ®çš„èŒƒå›´
13. ReduceTask å°†æ•°æ®ä»å„ä¸ª MapTask æœåŠ¡å™¨**ä¸‹è½½**ï¼ˆReduceTask ä¸»åŠ¨ï¼‰åˆ°æœ¬åœ°ï¼Œé»˜è®¤ä¼šå…ˆæ”¾åœ¨å†…å­˜ï¼Œè¾¾åˆ°ä¸€å®šé˜ˆå€¼ä¼šæº¢å†™åˆ°ç£ç›˜ï¼Œå¹¶è¿›è¡Œå½’å¹¶æ’åºå¤„ç†
14. æ¯æ¬¡è¯»å…¥ä¸€ç»„æ•°æ®ï¼Œäº¤ç»™ Reduce ç¨‹åºè¿›è¡Œå¤„ç†
15. è¿˜**å¯ä»¥**å¯¹ç»„å†…çš„æ•°æ®è¿›è¡Œæ’åºå¤„ç†
16. Reducer å°†æ•°æ®å¤„ç†ç»“æŸåé€šè¿‡ OutPutFormat å°†æ–‡ä»¶ä¿å­˜åˆ°ç›®æ ‡ä½ç½®

**è¾“å…¥æ•°æ®å¤„ç†**

åœ¨ WordCount çš„ç¤ºä¾‹ä¸­ï¼Œå¯¹äºæ–‡æœ¬æ–‡ä»¶çš„åˆ‡åˆ†é»˜è®¤ä½¿ç”¨ TextInputFormat å¯¹æ–‡æœ¬è¿›è¡Œåˆ‡åˆ†ï¼Œç„¶åå¯¹æ¯è¡Œè°ƒç”¨ Mapper çš„ map æ–¹æ³•æ¥è¿›è¡Œå¤„ç†ã€‚é™¤ TextInputFormat ä¹‹å¤–ï¼Œè¿˜æœ‰ CombineInputFormatã€SequenceInputFormatã€KeyValueInputFormat ç­‰ï¼Œä¹Ÿå¯ä»¥è‡ªå®šä¹‰ InputFormatã€‚

**å¹¶è¡Œåº¦å†³å®šæœºåˆ¶**

åœ¨ Hadoop ä¸­çš„ä»»ä½•æ–‡ä»¶ä¼šè¢«åˆ†å—è¿›è¡Œå­˜å‚¨ï¼Œæ¯ä¸ªå—è¢«æˆä¸ºä¸€ä¸ª blockã€‚åœ¨è¿›è¡Œæ•°æ®å¤„ç†æ—¶è¿˜å°†è¿›è¡Œåˆ‡ç‰‡å¤„ç†ï¼Œæ¯ä¸ªåˆ‡ç‰‡å°†è¢«ä¸€ä¸ª MapperTask è¿è¡Œï¼Œå¹¶ä¸”åˆ‡ç‰‡è¿‡ç¨‹ä¸åˆ†å—æ²¡æœ‰å…³ç³»ï¼Œä¹Ÿå°±æ˜¯è¯´å³ä½¿åˆ†å—å¤§å°ä¸º 128Mbï¼Œåœ¨åˆ‡ç‰‡æ—¶ä¹Ÿå¯ä»¥æŒ‰ç…§ 100Mb è¿›è¡Œåˆ‡ç‰‡ï¼Œä½†æ˜¯**é»˜è®¤**åˆ‡ç‰‡å¤§å°ç­‰äºåˆ†å—å¤§å°ã€‚

![image-20230128143431643](Hadoop.assets/image-20230128143431643.png)

ä¸Šå›¾ä¸­çš„ä¸¤ç§æƒ…å†µå¯¹æ¯”ï¼Œå‡è®¾åˆ†å—å¤§å°ä¸º 128Mbã€‚å¦‚æœåˆ‡ç‰‡å¤§å°ä¸º 100Mb é‚£ä¹ˆå¯¹äºç¬¬ä¸€å—æ–‡ä»¶å‰©ä¸‹çš„ 28Mb æ–‡ä»¶å°†å’Œç¬¬äºŒå—çš„ 78Mb æ–‡ä»¶è¿›è¡Œæ‹¼æ¥å½¢æˆä»¥åˆ‡ç‰‡ï¼Œä»¥æ­¤ç±»æ¨ï¼Œè¿™æ ·ä¼šé€ æˆæœ‰å¤§é‡çš„æ•°æ®åœ¨æœåŠ¡å™¨ä¹‹é—´è¿›è¡Œç§»åŠ¨ï¼ˆå› ä¸ºä¸åŒçš„å—è¢«å­˜æ”¾åœ¨äº†ä¸åŒçš„æœåŠ¡å™¨ä¸Šï¼‰ï¼Œä¼šæµªè´¹èµ„æºã€‚å¦‚æœæŒ‰ç…§åˆ†å—å¤§å°è¿›è¡Œåˆ‡ç‰‡ï¼Œå°†ä¼šé¿å…è¯¥é—®é¢˜çš„å‘ç”Ÿï¼Œæ›´åŠ é«˜æ•ˆã€‚

**FileInputFormat**

![image-20230131125225909](Hadoop.assets/image-20230131125225909.png)

![image-20230131125402985](Hadoop.assets/image-20230131125402985.png)

![image-20230131125631370](Hadoop.assets/image-20230131125631370.png)

**CombineTextInputFormat**

![image-20230131131356282](Hadoop.assets/image-20230131131356282.png)

åœ¨ä¸€èˆ¬çš„ TextInputFormat ä¸­ï¼Œæ¯ä¸ªæ–‡ä»¶æ˜¯å•ç‹¬è¿›è¡Œåˆ‡ç‰‡å¤„ç†çš„ï¼Œä¹Ÿå°±æ˜¯è¯´å¦‚æœåˆ‡ç‰‡å¤§å°ä¸º 128Mbï¼Œå³ä½¿ä½ çš„æœ‰ 100 ä¸ªæ–‡ä»¶çš„æ€»å’Œä¸å¤Ÿ 128Mb ä¹Ÿä¼šåˆ‡ä¸º 100 ç‰‡ï¼Œè¿™æ ·å°±ä¼šå¯åŠ¨ 100 ä¸ª Mapper ä»»åŠ¡ï¼Œæ¯ä¸€ä¸ªå ç”¨ 1core 1G çš„èµ„æºï¼Œå°±ä¼šé€ æˆä¸¥é‡çš„èµ„æºæµªè´¹ã€‚

CombineTextInputFormat åœ¨è¿›è¡Œåˆ‡åˆ†æ—¶ï¼Œä¼šå…ˆå¯¹æ–‡ä»¶è¿›è¡Œå•ç‹¬åˆ‡ç‰‡ï¼Œç„¶åå¯¹æ¯ä¸ªç‰‡è¿›è¡Œåˆå¹¶æ“ä½œï¼Œè¿™æ ·å°±æ˜¯å‡å°‘ Mapper æ•°é‡ï¼Œæå‡æ•ˆç‡ã€‚

**ä»»åŠ¡æäº¤è¿‡ç¨‹**

å…·ä½“çš„ä»£ç æ‰§è¡Œè¿‡ç¨‹å¯ä»¥é€šè¿‡ debug è¿›è¡ŒæŸ¥çœ‹ï¼Œé€šè¿‡åœ¨ driver ç±»ä¸­çš„ `job.waitForCompletion` å¤„æ·»åŠ æ–­ç‚¹æ¥è¿›è¡Œ debugã€‚ä»¥ä¸‹æ˜¯æäº¤ä»»åŠ¡çš„æµç¨‹ï¼š

> 1.  é¦–å…ˆé€šè¿‡è‡ªå®šä¹‰çš„ Driver ç±»æ¥è¿›è¡Œé…ç½®æ‰€æœ‰çš„ä»»åŠ¡ä¿¡æ¯ï¼Œç„¶åé€šè¿‡ job.waitForCompletion(true) æ¥æäº¤ä»»åŠ¡
>
>     > 1.  é¦–å…ˆ job ç±»å°†æ£€æŸ¥ä»»åŠ¡çš„çŠ¶æ€ä¿¡æ¯æ˜¯å¦ç¬¦ä¸º DEFINEï¼Œå¦‚æœæ˜¯åˆ™è¿›æ‰§è¡Œä»»åŠ¡çš„æäº¤
>     >
>     >     > 1. åœ¨æäº¤è¿‡ç¨‹ä¸­ï¼Œé¦–å…ˆå°†ä¿è¯ä»»åŠ¡çš„çŠ¶æ€æ˜¯ DEFINE
>     >     > 2. é€šè¿‡ setUseNewAPI æ¥è®¾ç½® API çš„å…¼å®¹ã€‚
>     >     > 3. è·å–è¿æ¥ã€‚åœ¨è·å–è¿æ¥ä¸­ï¼Œä¼šæ ¹æ®ä»»åŠ¡çš„é…ç½®ä¿¡æ¯ç±»å†³å®šåœ¨é‚£é‡Œè¿è¡Œï¼Œé€šè¿‡è®¾ç½® LocalClientProtocolProvider æˆ– YarnClientProtocolProvider æ¥è®¾ç½®ä»»åŠ¡åœ¨é‚£é‡Œæ‰§è¡Œ
>     >     > 4.  åˆ›å»º JobSubmitter å¯¹è±¡å¹¶æäº¤ä»»åŠ¡
>     >     >
>     >     >     > 1. ç¬¬ä¸€éƒ¨å°†æ£€æŸ¥ç”¨æˆ·è®¾ç½®çš„è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼ˆè¾“å…¥è¾“å‡ºè·¯å¾„æ˜¯å¦å­˜åœ¨ï¼‰
>     >     >     > 2. è·å–ç”¨æˆ·çš„é…ç½®ï¼Œç”Ÿæˆ JobID å’Œå·¥ä½œçš„ç¼“å­˜ç›®å½•
>     >     >     > 3. å¯¹è¾“å…¥æ•°æ®è¿›è¡Œåˆ‡ç‰‡ï¼Œå¹¶å°†éœ€è¦çš„åˆ‡ç‰‡ä¿¡æ¯ï¼ˆè¿™é‡ŒçŸ¥è¯†é€»è¾‘åˆ‡ç‰‡ï¼Œå¹¶æ²¡æœ‰çœŸæ­£åˆ‡ç‰‡ï¼ŒçœŸæ­£åˆ‡ç‰‡çš„æ˜¯ InputFormatï¼‰æ”¾åœ¨ç¼“å­˜ç›®å½•ä¸­ï¼Œé€šè¿‡ writeConf æ–¹æ³•å°†é…ç½®å†™å‡ºåˆ° job.xml ä¸­
>     >     >     > 4. æœ€åæäº¤ä»»åŠ¡ï¼Œæäº¤ä»»åŠ¡åç¼“å­˜ç›®å½•å°†è¢«åˆ é™¤
>     >     > 5. å°†ä»»åŠ¡çš„çŠ¶æ€è®¾ç½®ä¸º RUNNING
>     > 2. å¼€å§‹ç›‘æ§ä»»åŠ¡çŠ¶æ€ï¼Œç­‰å¾…ç»“æŸåè¿”å›è¿”å›ç»“æœçŠ¶æ€
> 2. æ˜¾ç¤ºä»»åŠ¡æ˜¯å¦æ‰§è¡ŒæˆåŠŸ

**Shuffle**

Shuffle æ˜¯ä¸€ä¸ªæ¯”è¾ƒå¤æ‚çš„è¿‡ç¨‹ï¼Œåœ¨è¿™ä¸ªé˜¶æ®µï¼Œå¯ä»¥å¯¹ Mapper çš„è¾“å‡ºç»“æœè¿›è¡Œæ’åºï¼Œå‹ç¼©ï¼Œåˆ†åŒºç­‰æ“ä½œï¼Œç„¶åå°†å¤„ç†åçš„æ•°æ®äº¤ç»™ Reduce å¤„ç†ã€‚æµç¨‹å¦‚ä¸‹ï¼š

![image-20230131202844229](Hadoop.assets/image-20230131202844229.png)

**Partitioner**

æˆ‘ä»¬çŸ¥é“åœ¨ Map é˜¶æ®µä¸€ä¸ªä»»åŠ¡å°†è¢«æ‹†åˆ†ï¼Œç”±å¤šä¸ª MapTask è¿›è¡Œæ‰§è¡Œï¼Œåœ¨ Redcue é˜¶æ®µï¼Œä¹Ÿä¼šæœ‰å¤šä¸ªä»»åŠ¡åŒæ—¶è¿›è¡Œï¼Œæ¯ä¸€ä¸ªåˆ†åŒºå°†ä¼šå¯¹åº”ä¸€ä¸ª RedcueTaskã€‚ReduceTask çš„æ•°é‡ä¼šå—åˆ° Partitioner æ•°é‡çš„å½±å“ã€‚å…·ä½“æºç å¦‚ä¸‹ï¼š

```java
// å¦‚æœè®¾ç½®çš„åˆ†åŒºæ•°å¤§äº 1 ä¼šæ‰§è¡Œè‡ªå®šä¹‰çš„ Partitionerï¼Œå¦‚æœæ²¡æœ‰è‡ªå®šä¹‰ä¼šä½¿ç”¨é»˜è®¤çš„ HashPartitioner
if (partitions > 1) {
    partitioner = (org.apache.hadoop.mapreduce.Partitioner<K,V>)
        ReflectionUtils.newInstance(jobContext.getPartitionerClass(), job);
} else {
    
    // å¦‚æœè®¾ç½® ReduceTask çš„ä»»åŠ¡æ•°é‡ä¸º 0ï¼Œå°†æ²¡æœ‰ Shuffleã€Reucde é˜¶æ®µï¼Œç›´æ¥è¾“å‡º Map é˜¶æ®µçš„ç»“æœ
    // å¦‚æœè®¾ç½®çš„ ReduceTask ä»»åŠ¡æ•°å¤§äº 1 ä½†æ˜¯å°äºåˆ†åŒºæ•°ï¼Œä¼šå‡ºç° IO å¼‚å¸¸
    
    // å¦‚æœè®¾ç½®çš„ partitioners ä¸º 1ï¼Œå°†ä¸ä½¿ç”¨è‡ªå®šä¹‰çš„ Partitionerï¼Œç›´æ¥ç”Ÿæˆä¸€ä¸ªåˆ†åŒº
    partitioner = new org.apache.hadoop.mapreduce.Partitioner<K,V>() {
        @Override
        public int getPartition(K key, V value, int numPartitions) {
            return partitions - 1;
        }
    };
    
    //å¦‚æœ ReducerTask ä»»åŠ¡æ•°é‡å¤§äºåˆ†åŒºæ•°ï¼Œå°†ä¼šäº§ç”Ÿç©ºæ–‡ä»¶
}
```

**æ³¨æ„**ï¼šè‡ªå®šä¹‰çš„ Partitioner ç¼–å·å¿…é¡»ä» 0 å¼€å§‹ï¼Œå¹¶ä¸”è¦**è¿ç»­**ï¼Œä¸èƒ½è·³å·ã€‚

**æ’åº**

MapTask é˜¶æ®µ

> 1. å®ƒä¼šå°†å¤„ç†çš„ç»“æœæš‚æ—¶æ”¾åˆ°ç¯å½¢ç¼“å†²åŒºä¸­ï¼Œå½“ç¯å½¢ç¼“å†²åŒºä½¿â½¤ç‡è¾¾åˆ°â¼€å®šé˜ˆå€¼åï¼Œå†å¯¹ç¼“å†²åŒºä¸­çš„æ•°æ®è¿›è¡Œâ¼€æ¬¡å¿«é€Ÿæ’åºï¼Œå¹¶å°†è¿™äº›æœ‰åºæ•°æ®æº¢å†™åˆ°ç£ç›˜ä¸Šã€‚
> 2. æº¢å†™å®Œæ¯•åï¼Œå®ƒä¼šå¯¹ç£ç›˜ä¸Šæ‰€æœ‰æ–‡ä»¶è¿›è¡Œå½’å¹¶æ’åºã€‚

ReduceTask é˜¶æ®µ

å½“æ‰€æœ‰æ•°æ®æ‹·è´å®Œæ¯•åï¼ŒReduceTask ç»Ÿä¸€å¯¹å†…å­˜å’Œç£ç›˜ä¸Šçš„æ‰€æœ‰æ•°æ®è¿›è¡Œâ¼€æ¬¡å½’å¹¶æ’åºã€‚

> 1. éƒ¨åˆ†æ’åºï¼šMapReduce æ ¹æ®è¾“â¼Šè®°å½•çš„é”®å¯¹æ•°æ®é›†æ’åºã€‚ä¿è¯è¾“å‡ºçš„æ¯ä¸ªâ½‚ä»¶å†…éƒ¨æœ‰åºã€‚
> 2. å…¨å±€æ’åºï¼šæœ€ç»ˆè¾“å‡ºç»“æœåªæœ‰â¼€ä¸ªâ½‚ä»¶ï¼Œä¸”â½‚ä»¶å†…éƒ¨æœ‰åºã€‚å®ç°â½…å¼æ˜¯åªè®¾ç½®ä¸€ä¸ª ReduceTaskã€‚ä½†è¯¥â½…æ³•åœ¨å¤„ç†â¼¤å‹â½‚ä»¶æ—¶æ•ˆç‡æä½ï¼Œå› ä¸ºä¸€å°æœºå™¨å¤„ç†æ‰€æœ‰â½‚ä»¶ï¼Œå®Œå…¨ä¸§å¤±äº† MapReduce æ‰€æä¾›çš„å¹¶â¾æ¶æ„ã€‚
> 3. è¾…åŠ©æ’åºï¼š(GroupingComparator åˆ†ç»„)åœ¨ Reduce ç«¯å¯¹ key è¿›â¾åˆ†ç»„ã€‚åº”â½¤äºï¼šåœ¨æ¥æ”¶çš„ key ä¸º bean å¯¹è±¡æ—¶ï¼Œæƒ³è®©â¼€ä¸ªæˆ–â¼ä¸ªå­—æ®µç›¸åŒ(å…¨éƒ¨å­—æ®µâ½è¾ƒä¸ç›¸åŒ)çš„ key è¿›â¼Šåˆ°åŒâ¼€ä¸ª reduce â½…æ³•æ—¶ï¼Œå¯ä»¥é‡‡â½¤åˆ†ç»„æ’åºã€‚
> 4. äºŒæ¬¡æ’åºï¼šåœ¨â¾ƒå®šä¹‰æ’åºè¿‡ç¨‹ä¸­ï¼Œå¦‚æœ compareTo ä¸­çš„åˆ¤æ–­æ¡ä»¶ä¸ºä¸¤ä¸ªå³ä¸ºäºŒæ¬¡æ’åºã€‚

**æ¡ˆä¾‹**

1.  å¯¹ FlowBean çš„ç¨‹åºè¾“å‡ºæŒ‰ç…§æ€»æµé‡è¿›è¡Œå€’åºæ’åº

    > ç›´æ¥å®ç°æ—¶ä¸èƒ½å®ç°çš„ï¼Œå¯ä»¥å°† FlowBean çš„è¾“å‡ºä½œä¸ºæœ¬æ¡ˆä¾‹çš„è¾“å…¥ï¼Œç„¶åå°† FlowBean ç±»ä½œä¸º keyï¼Œå®ç° WritableComparableï¼Œç„¶åè¿›è¡Œæ’åºå°±å¯ä»¥äº†ã€‚
2.  åœ¨å€’å™æ’åºçš„åŸºç¡€ä¸Šè¿›è¡ŒæŒ‰ç…§æ‰‹æœºå·åˆ†åŒº

    > åœ¨æ¡ˆä¾‹ 1 çš„åŸºç¡€ä¸Šè¿›è¡Œè‡ªå®šä¹‰ Partitioner å°±å¯ä»¥äº†ã€‚

è¿™ä¸¤ä¸ªæ¡ˆä¾‹æ¯”è¾ƒç®€å•ï¼Œå°±ä¸æ¼”ç¤ºäº†ã€‚

**Combiner**

ç”±ä¸Šè¾¹çš„ Shuffle çš„æµç¨‹å›¾æ‰€ç¤ºï¼ŒCombiner æ˜¯ä¸€ä¸ªå¯é€‰çš„è¿‡ç¨‹ï¼Œå¹¶ä¸æ˜¯å¿…é¡»çš„ç»„ä»¶ã€‚è®¾ç½® Combiner å¯ä»¥å°† Mapper çš„è¾“å‡ºç»“æœè¿›è¡Œé¢„èšåˆï¼Œä»è€Œé™ä½åœ¨æœåŠ¡å™¨ä¹‹é—´ä¼ è¾“çš„æˆæœ¬ã€‚Combiner æœ¬è´¨ä¸ Reducer ä¸€æ ·ï¼Œåªä¸è¿‡æ˜¯æ‰§è¡Œåœ¨ Map é˜¶æ®µï¼Œæ‰€ä»¥è‡ªå®šä¹‰çš„ Combiner åŒæ ·æ˜¯ç»§æ‰¿ Reducer ç±»ï¼Œç„¶åé€šè¿‡ `job.setCombinerClass()` æ¥è®¾ç½®ï¼Œé€šå¸¸ç›´æ¥è®¾ç½®æˆè‡ªå®šä¹‰çš„ Reducer ç±»å°±å¯ä»¥ã€‚è¿™é‡ŒåŒæ ·æ˜¯ä¸

**è¾“å‡ºæ•°æ®å¤„ç†**

OutputFormat è´Ÿè´£å°†è®¡ç®—äº§ç”Ÿçš„ç»“æœè¿›è¡Œè¾“å‡ºï¼Œè¾“å‡ºçš„ç›®æ ‡ä¸ä¸€å®šæ˜¯æ–‡ä»¶ï¼Œä¹Ÿå¯èƒ½æ˜¯ MySQLã€HBase ç­‰å…¶ä»–ä»‹è´¨ã€‚ç”¨æˆ·yä¹Ÿå¯ä»¥é€šè¿‡è‡ªå®šä¹‰ OutPutFormat ç»„ä»¶æ¥å®ç°è‡ªå·±çš„åŠŸèƒ½ï¼Œç³»ç»Ÿé»˜è®¤ä½¿ç”¨ FileOutputFormatã€‚

**ç¤ºä¾‹**

ç»™å‡ºå¦‚ä¸‹çš„ç½‘å€æ–‡ä»¶ï¼Œå°†å¸¦æœ‰ atguigu çš„ç½‘å€æ”¾åˆ°å•ç‹¬çš„æ–‡ä»¶ä¸­ã€‚

```
http://www.atguigu.com
http://www.google.com
http://www.baidu.com
http://www.atguigu.com
```

Mapper å’Œ Reducer è¿™é‡Œå°±ä¸è¿‡å¤šå±•ç¤ºäº†ï¼Œä¸‹é¢æ˜¯è‡ªå®šä¹‰çš„ LogFileOutputFormat å’Œ LogRecordWrite

```java

// å…¶å®è¿™ä¸ªç±»åªæ˜¯ä¸€ä¸ªå£³ï¼Œå¹¶æ²¡æœ‰çœŸæ­£çš„å†™å‡ºæ•°æ®ï¼Œè€Œæ˜¯é€šè¿‡è¿™ä¸ªç±»è·å–ä¸€ä¸ª RecordWriter ç±»æ¥çœŸæ­£çš„è¿›è¡Œè¾“å‡º
// ä¸ºå•¥è¦è¿™æ ·è®¾è®¡å‘¢ï¼Ÿ
public class LogFileOutputFormat extends FileOutputFormat<Text, NullWritable> {
    @Override
    public RecordWriter<Text, NullWritable> getRecordWriter(TaskAttemptContext job) throws IOException, InterruptedException {
        return new LogRecordWrite(job);
    }
}
```

```java
// è¿™æ˜¯çœŸæ­£å‘å¤–è¾“å‡ºæ•°æ®çš„ç±»ï¼Œæ³›å‹æ˜¯è¾“å…¥æ•°æ®çš„ç±»å‹
public class LogRecordWrite extends RecordWriter<Text, NullWritable> {
    private final FSDataOutputStream atguiguOut;
    private final FSDataOutputStream otherOut;

    // ä¸€ä¸ªæ„é€ å™¨ï¼Œä¼ è¿‡æ¥çš„æ˜¯ contextï¼Œé‡Œé¢åŒ…å«äº†ä»»åŠ¡ä¿¡æ¯
    public LogRecordWrite(TaskAttemptContext context) {
        try {

            // é€šè¿‡ context çš„é…ç½®ä¿¡æ¯åˆ›å»ºä¸€ä¸ª FS çš„å¯¹è±¡ï¼Œç”¨æ¥è¾“å‡ºæ•°æ®ï¼Œè¿™é‡Œä¸èƒ½ç”¨ java.io åŒ…ä¸‹çš„ï¼Œå› ä¸ºç”Ÿäº§ç¯å¢ƒä¼šå­˜æ”¾åœ¨ Hadoop é›†ç¾¤ä¸Š
            FileSystem fileSystem = FileSystem.get(context.getConfiguration());

            // åˆ›å»ºè¿ä¸ªæµ
            this.atguiguOut = fileSystem.create(new Path("/home/zh/hadoop/output/002/atguigu"));
            this.otherOut = fileSystem.create(new Path("/home/zh/hadoop/output/002/other"));
        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }

    @Override
    public void write(Text key, NullWritable value) {
        String log = key.toString();
        try {
            if (log.contains("atguigu")) {
                this.atguiguOut.writeBytes(log + "\n");
            } else {
                this.otherOut.writeBytes(log + "\n");
            }
        } catch (IOException e) {
            throw new RuntimeException(e);
        }

    }

    @Override
    public void close(TaskAttemptContext context) {
        IOUtils.closeStream(this.atguiguOut);
        IOUtils.closeStream(this.otherOut);
    }
}
```

**MapTask å·¥ä½œæœºåˆ¶**

**ç®€è¿°**

MapReduce ç¨‹åºä¸»è¦åˆ†ä¸ºè¿ä¸ªé˜¶æ®µï¼šMapTask å’Œ RecudeTaskã€‚MapTask é˜¶æ®µä¸»è¦è®²è¾“å…¥æ–‡ä»¶è¿›è¡Œåˆ‡ç‰‡å¤„ç†å¹¶è®¡ç®—ï¼Œå¹¶é€šè¿‡ Shuflle æœºåˆ¶å¯¹æ•°æ®è¿›è¡Œæ’åºï¼Œä¸º ReduceTask åšå‡†å¤‡ã€‚

åœ¨ Hadoop ä¸­ï¼Œä¸»è¦æ˜¯ç”± MapTask ç±»è¿›è¡Œå®ç°çš„ï¼Œä¸»è¦åŒ…å«äº† Readã€Mapã€Collectã€æº¢å†™ã€Merge äº”ä¸ªé˜¶æ®µï¼Œæœ€å Merge é˜¶æ®µäº§ç”Ÿçš„è¾“å‡ºæ–‡ä»¶å°†è¢« ReduceTask æ‹‰å–ã€‚

![image-20230212120259916](Hadoop.assets/image-20230212120259916.png)

**MapTask å·¥ä½œæµç¨‹**

> 1.  åˆå§‹åŒ–è¾“å…¥æ–‡ä»¶
>
>     > 1. è¯»å…¥è¾“å…¥æ–‡ä»¶ï¼Œå¯¹æ–‡ä»¶è¿›è¡Œç‰©ç†åˆ‡åˆ†
> 2.  æ‰§è¡Œ Mapper
>
>     > 1. åˆå§‹åŒ– Mapper å¯¹è±¡
>     > 2. å¾ªç¯å¯¹æ¯ä¸€ç»„ KV è°ƒç”¨è‡ªå®šä¹‰ Mapper çš„ map æ–¹æ³•
>     > 3. æŒ‰ç…§ä¸šåŠ¡é€»è¾‘å¯¹æ•°æ®è¿›è¡Œå¤„ç†
>     > 4.  é€šè¿‡ context å¯¹è±¡å°†å¤„ç†çš„æ•°æ®è¿›è¡Œå†™å‡º
>     >
>     >     > 1. æ£€æŸ¥å†™å‡ºçš„ KV ç±»å‹å’Œé¢„è®¾çš„ç±»å‹æ˜¯å¦ç›¸ç¬¦ï¼Œæ£€æŸ¥åˆ†åŒºç¼–å·æ˜¯å¦æ­£å¸¸ï¼Œå¦‚æœä¸ç¬¦åˆå°†æŠ›å‡ºå¼‚å¸¸
>     >     > 2. å¯¹ KV è¿›è¡Œåºåˆ—åŒ–ï¼Œå¹¶å°† indexã€partitionã€keystarã€valstart æ”¾å…¥ç¯å½¢ç¼“å†²åŒºçš„ Meta åŒºåŸŸï¼›å°† Keyã€Valueã€unused æ”¾å…¥ç¯å½¢ç¼“å†²åŒºçš„ Records åŒºåŸŸ
> 3. å…³é—­è¾“å…¥èµ„æº
> 4.  å…³é—­ mapperContext
>
>     > 1.  å¯¹ç¯å½¢ç¼“å†²åŒºçš„æ•°æ®è¿›è¡Œæ’åºæº¢å†™
>     >
>     >     > 1. åˆ›å»ºä¸´æ—¶å·¥ä½œç©ºé—´å¹¶åˆ›å»ºè¾“å…¥æµ
>     >     > 2. å¯¹ç¼“å†²åŒºå†…çš„æ•°æ®è¿›è¡Œå¿«é€Ÿæ’åº
>     >     > 3. å¾ªç¯æ¯ä¸€ä¸ªåˆ†åŒºï¼Œå°†æ•°æ®æº¢å†™åˆ°æ–‡ä»¶
>     > 2. å¯¹åˆ†åŒºè¿›è¡Œå½’å¹¶æ’åº

**ReduceTask å·¥ä½œæœºåˆ¶**

**ç®€ä»‹**

ReduceTask åœ¨ MapTask ä¹‹åï¼Œä¸»è¦åˆ†ä¸ºä¸‰ä¸ªé˜¶æ®µï¼šCopyã€Sortã€Reduceã€‚åœ¨ MapTask é˜¶æ®µçš„åˆ†åŒºæ•°é‡å°†å†³å®š ReduceTask çš„å¹¶è¡Œåº¦ï¼Œä¹Ÿå¯ä»¥æ²¡æœ‰ ReduceTask é˜¶æ®µï¼Œç›´æ¥å°† MapTask é˜¶æ®µçš„ç»“æœè¾“å‡ºã€‚

![image-20230212165625544](Hadoop.assets/image-20230212165625544.png)

![image-20230212170151067](Hadoop.assets/image-20230212170151067.png)

**ReduceTask å·¥ä½œæµç¨‹**

> 1. æ·»åŠ  copyã€sortã€reduce ä¸‰ä¸ªé˜¶æ®µåˆ° progressï¼Œæ¯å®Œæˆä¸€ä¸ªé˜¶æ®µå°±ä¼šè¿›è¡Œæ ‡è®°
> 2.  è®¾ç½®æ–° API çš„å…¼å®¹ï¼Œåˆå§‹åŒ– ReduceTask å¯¹è±¡
>
>     > 1. è·å– OutputFormat å®ä¾‹ï¼Œé»˜è®¤æ˜¯ TextOutputFormat
> 3.  åˆ›å»º shuffleConsumerPlugin å¯¹è±¡ï¼Œå¹¶è¿›è¡Œåˆå§‹åŒ–æ“ä½œ
>
>     > 1.  åˆå§‹åŒ–å‚æ•°ï¼Œåˆ›å»º ShuffleSchedulerImpl å¯¹è±¡
>     >
>     >     > 1. è·å–æ‰€æœ‰çš„ MapTask æ•°é‡æ¥æ–¹ä¾¿æŠ“å–
>     > 2.  åˆ›å»º MergeManager å¯¹è±¡
>     >
>     >     > 1. åˆ†åˆ«åˆ›å»º MemoryMerger å’Œ DiskMerger æ¥å½’å¹¶å†…å­˜å’Œç£ç›˜ä¸Šçš„æ•°æ®
> 4.  æ‰§è¡Œ shuffleConsumerPlugin çš„ run æ–¹æ³•
>
>     > 1. åœ¨å…¶ä¸­å°†è¿›è¡Œæ•°æ®çš„æŠ“å–å’Œæ’åºçš„å·¥ä½œ
> 5.  æ‰§è¡Œè‡ªå®šçš„ Reducer
>
>     > 1. åˆå§‹åŒ– Reducer å¯¹è±¡
>     > 2. å¯¹æ•°æ®çš„æ²¡æœ‰ç»™ key è°ƒç”¨ Reducer çš„é€»è¾‘
>     > 3. å°†æ•°æ®è¿›è¡Œè¾“å‡º
> 6. è¿è¡Œç»“æŸ

**Join è®¡ç®—**

**ä»€ä¹ˆæ˜¯ Join**

åœ¨æ•°æ®åº“æŸ¥è¯¢è¿‡ç¨‹ä¸­ï¼Œæœ‰æ—¶éœ€è¦ç”¨åˆ° join è¯­å¥æ¥å¯¹ä¸åŒçš„è¡¨è¿›è¡Œè¿æ¥ï¼Œæ¥å®ç°æ•°æ®çš„å±•ç¤ºã€‚åœ¨å¤§æ•°æ®å¤„ç†è¿‡ç¨‹å¾€å¾€ä¹Ÿéœ€è¦è¿›è¡ŒåŒæ ·çš„æ“ä½œï¼Œæ¯”å¦‚ä¸‹é¢çš„ä¾‹å­ï¼š

ç°åœ¨æœ‰ä¸¤ä¸ªæ–‡ä»¶ï¼Œåˆ†åˆ«å­˜æ”¾äº†è®¢å•æ•°æ®å’Œå•†å“åç§°æ•°æ®ï¼Œç°åœ¨å°†è¦å°†è®¢å•å’Œå•†å“åç§°è¿›è¡Œå…³è”ã€‚

```
# order æ•°æ®ï¼Œåˆ†åˆ«æ˜¯ è®¢å•ç¼–å·ã€å•†å“ç¼–å·ã€æ•°é‡
1000001	01	1
1000002	01	3
1000003	02	2
1000004	01	3

# pid æ•°æ®ï¼Œåˆ†åˆ«æ˜¯ å•†å“ç¼–å·ã€å•†å“åç§°
01	å°ç±³
02	åä¸º

# é¢„è¾“å‡ºç»“æœ
1000004 å°ç±³    3
1000002 å°ç±³    3
1000001 å°ç±³    1
1000003 åä¸º    2
```

**è§£å†³æ€è·¯**

åœ¨ MapperTask æ‰§è¡ŒåŸç†ä¸­å¯ä»¥çœ‹åˆ°ï¼Œåœ¨æ‰§è¡Œ Mapper ä¹‹å‰ä¼šå…ˆå¯¹ Mapper å¯¹è±¡è¿›è¡Œåˆå§‹åŒ–æ“ä½œï¼Œè¿™ä¸ªæ—¶å€™ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ context å¯¹è±¡æ¥å¾—çŸ¥æ•°æ®æ˜¯ä»é‚£ä¸ªæ–‡ä»¶ä¼ è¾“è¿‡æ¥çš„ï¼Œé€šè¿‡è§‚å¯Ÿä¸Šè¾¹çš„æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥å°†å•†å“ç¼–å·åˆ—ä½œä¸º Mapper è¾“å‡ºçš„ Keyï¼Œå¹¶å°†å…¶ä»–æ•°æ®å°è£…æˆä¸€ä¸ªç±»ï¼ˆä¸ç®¡æ˜¯é‚£ä¸ªæ–‡ä»¶çš„æ•°æ®ï¼Œéƒ½å¡åœ¨åŒä¸€ä¸ªå¯¹è±¡é‡Œï¼‰ï¼Œç„¶åä¼ é€’ç»™ Reducer è¿›è¡Œå¤„ç†ã€‚åœ¨ Reducer ä¸­å†å°†åç§°èµ‹å€¼ç»™æ‰€æœ‰çš„å¯¹è±¡ã€‚

**ä»£ç ç¤ºä¾‹**

```java
public class TableBean implements Writable {

    private String order;
    private String pid;
    private int amount;
    private String name;
    private String flag;

   	// getter and setter

    @Override
    public void write(DataOutput out) throws IOException {
        out.writeUTF(this.order);
        out.writeUTF(this.pid);
        out.writeInt(this.amount);
        out.writeUTF(this.name);
        out.writeUTF(this.flag);
    }

    @Override
    public void readFields(DataInput in) throws IOException {
        this.order = in.readUTF();
        this.pid = in.readUTF();
        this.amount = in.readInt();
        this.name = in.readUTF();
        this.flag = in.readUTF();
    }

    @Override
    public String toString() {
        return this.order + "\t" + this.name + "\t" + this.amount;
    }
}

```

```java
public class JoinMapper extends Mapper<LongWritable, Text, Text, TableBean> {

    private String flag;
    private final Text outKey = new Text();
    private final TableBean outValue = new TableBean();

    @Override
    public void setup(Context context) {
        FileSplit fileSplit = (FileSplit) context.getInputSplit();
        this.flag = fileSplit.getPath().getName();
    }

    @Override
    public void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, TableBean>.Context context) throws IOException, InterruptedException {
        String[] split = value.toString().split("\t");
        this.outValue.setFlag(this.flag);

        // ä¸ç®¡æ˜¯é‚£ä¸ªè¡¨çš„æ•°æ®éƒ½å¡åœ¨ TableBean
        if (this.flag.contains("order")) {
            this.outValue.setOrder(split[0]);
            this.outValue.setPid(split[1]);
            this.outValue.setAmount(Integer.parseInt(split[2]));
            this.outValue.setName(""); // ç”±äºè¦è¿›è¡Œè¾“å‡ºï¼Œæ‰€ä»¥ä¸èƒ½æœ‰ nullï¼Œæ‰€ä»¥è¦èµ‹ç©ºå€¼
        } else {
            this.outValue.setOrder("");
            this.outValue.setPid(split[0]);
            this.outValue.setAmount(0);
            this.outValue.setName(split[1]);
        }
        this.outKey.set(this.outValue.getPid());
        context.write(this.outKey, this.outValue);
    }
}

```

```java
public class JoinReducer extends Reducer<Text, TableBean, TableBean, NullWritable> {
    @Override
    public void reduce(Text key, Iterable<TableBean> values, Reducer<Text, TableBean, TableBean, NullWritable>.Context context) throws IOException, InterruptedException {
        TableBean nameBean = new TableBean();
        List<TableBean> beans = new LinkedList<>();

        // éå†æ‰€æœ‰çš„å¯¹è±¡ï¼Œå°†æ ‡è®°äº†åç§°çš„å¯¹è±¡æ‰¾å‡ºæ¥
        for (TableBean value : values) {
            if (value.getFlag().contains("order")) {
                TableBean bean = new TableBean();
                try {
                    BeanUtils.copyProperties(bean, value); // è¿™é‡Œè¦å¯¹è±¡å¤åˆ¶ï¼Œå¹¶ä¸èƒ½ç›´æ¥æ·»åŠ  value å¯¹è±¡ï¼Œå› ä¸ºæ¯æ¬¡è¿”å›çš„ value å¯¹è±¡ç›¸åŒï¼Œåªæ˜¯çŠ¶æ€ä¸åŒ
                    beans.add(bean);
                } catch (IllegalAccessException | InvocationTargetException e) {
                    throw new RuntimeException(e);
                }
            } else {
                try {
                    BeanUtils.copyProperties(nameBean, value);
                } catch (IllegalAccessException | InvocationTargetException e) {
                    throw new RuntimeException(e);
                }
            }
        }

        // å¾ªç¯è¾“å‡ºæ¯ä¸€ä¸ªå¯¹è±¡
        for (TableBean bean : beans) {
            bean.setName(nameBean.getName()); //  è®°å¾—è®¾ç½®åç§°
            context.write(bean, NullWritable.get());
        }
    }
}
```

**MapJoin**

åœ¨åˆšåˆšçš„å®ä¾‹ä¸­ï¼Œå­˜åœ¨ä¸€ä¸ªæ¯”è¾ƒæ˜æ˜¾çš„é—®é¢˜ï¼Œå°±æ˜¯å¦‚æœ order è¡¨çš„ä¸€ä¸ª pid æ¡æ•°è¿‡å¤šå°†ä¼šå‘ç”Ÿæ•°æ®å€¾æ–œã€‚åƒè¿™ç§ä¸€ä¸ªå¤§è¡¨å’Œä¸€ä¸ªå°è¡¨çš„æƒ…å†µä¸‹ï¼Œå¯ä»¥å°†å°è¡¨è¿›è¡Œç¼“å­˜ï¼Œç„¶ååœ¨å¤„ç†å¤§è¡¨çš„æ—¶å€™å°† pid è¿›è¡Œ join æ“ä½œã€‚

```java
public class MapJoinMapper extends Mapper<LongWritable, Text, Text, NullWritable> {

    private final Map<String, String> map = new HashMap<>();
    private final Text outKey = new Text();
    
    @Override
    protected void setup(Mapper<LongWritable, Text, Text, NullWritable>.Context context) throws IOException {
        
        // åœ¨ setup ä¸­å¯¹ç¼“å­˜æ–‡ä»¶è¿›è¡Œå¤„ç†ï¼Œæ·»åŠ  Map ä¸­æ–¹ä¾¿ä½¿ç”¨
        URI[] cacheFiles = context.getCacheFiles();
        FileSystem fileSystem = FileSystem.get(context.getConfiguration());
        FSDataInputStream fsDataInputStream = fileSystem.open(new Path(cacheFiles[0]));
        BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(fsDataInputStream, StandardCharsets.UTF_8));

        String line;
        while (StringUtils.isNotEmpty(line = bufferedReader.readLine())) {
            String[] split = line.split("\t");
            this.map.put(split[0], split[1]);
        }
    }

    @Override
    protected void map(LongWritable key, Text value, Mapper<LongWritable, Text, Text, NullWritable>.Context context) throws IOException, InterruptedException {
        String[] split = value.toString().split("\t");
        
        // é€šè¿‡åˆšåˆšçš„ç¼“å­˜å¯¹æ–‡ä»¶è¿›è¡Œ join æ“ä½œ
        this.outKey.set(split[0] + "\t" + this.map.get(split[1]) + "\t" + split[2]);
        context.write(this.outKey, NullWritable.get());
    }
}
```

```java
public class MapJoinDriver {
    public static void main(String[] args) throws IOException, InterruptedException, ClassNotFoundException, URISyntaxException {
        Job job = Job.getInstance(new Configuration());
        job.setJarByClass(MapJoinDriver.class);

        job.setMapOutputKeyClass(Text.class);
        job.setMapOutputValueClass(NullWritable.class);
        job.setMapperClass(MapJoinMapper.class);

        FileInputFormat.setInputPaths(job, new Path("/home/zh/hadoop/input/004/input"));
        FileOutputFormat.setOutputPath(job, new Path("/home/zh/hadoop/output/004"));

        // è®¾ç½®éœ€è¦ç¼“å­˜çš„æ–‡ä»¶
        job.addCacheFile(new URI("file:///home/zh/hadoop/input/004/catch/pid"));

        // è¿™ä¸ªæ¯”è¾ƒç®€å•ï¼Œä¸è¿›è¡Œ Reduce æ“ä½œ
        job.setNumReduceTasks(0);
        
        boolean res = job.waitForCompletion(true);
        System.out.println(res ? "success" : "fail");
        System.exit(res ? 0 : 1);
    }
}
```

**ETL æ¸…æ´—**

**ä»€ä¹ˆæ˜¯ ETL æ¸…æ´—**

è¿™ä¸ªå…¶å®å¾ˆç®€å•ï¼Œå°±æ˜¯åœ¨ Mapper ä¸­å¯¹æ•°æ®è¿›è¡Œè¿‡æ»¤ã€‚å°†éœ€è¦çš„æ•°æ®é€šè¿‡ context è¿›è¡Œ writeï¼Œä¸éœ€è¦çš„æ•°æ®ä¸è¿›è¡Œ write æ“ä½œå°±å¥½äº†ã€‚

**å¸¸ç”¨æ­£åˆ™è¡¨è¾¾å¼**

è¿™ç§ä¸œè¥¿ç™¾åº¦ä¸€æœä¸€å¤§æŠŠï¼Œæˆ‘å°±å°±ä¸è¿›è¡Œæ•´ç†äº†ï¼Œ[è¿™é‡Œ](https://www.rongcloud.cn/blog/?p=5818)ç»™å‡ºä¸ªæœç´¢ç»“æœï¼Œæ„Ÿè§‰è¿˜æŒºå…¨çš„ã€‚

#### Hadoop å‹ç¼©

**æœ‰å“ªäº›å‹ç¼©ç®—æ³•**

|   å‹ç¼©æ ¼å¼  | æ˜¯å¦è‡ªå¸¦ |    ç®—æ³•   |    æ‰©å±•å   | æ˜¯å¦å¯åˆ‡ç‰‡ |    å¯ç”¨åæ˜¯å¦éœ€è¦ä¿®æ”¹ç¨‹åº   |
| :-----: | :--: | :-----: | :------: | :---: | :--------------: |
| DEFAULT |   æ˜¯  | DEFAULT | .default |   å¦   |   å’Œæ–‡æœ¬å¤„ç†ä¸€æ ·ï¼Œä¸éœ€è¦å¤„ç†  |
|   Gzip  |   æ˜¯  | DEFAULT |    .gz   |   å¦   |   å’Œæ–‡æœ¬å¤„ç†ä¸€æ ·ï¼Œä¸éœ€è¦å¤„ç†  |
|  bzip2  |   æ˜¯  |  bzip2  |   .bz2   |   æ˜¯   |   å’Œæ–‡æœ¬å¤„ç†ä¸€æ ·ï¼Œä¸éœ€è¦å¤„ç†  |
|   LZO   |   å¦  |   LZO   |   .lzo   |   æ˜¯   | éœ€è¦å»ºç«‹æ‰€ä»¥ï¼Œè¿˜éœ€è¦æŒ‡å®šè¾“å…¥æ ¼å¼ |
|  Snappy |   æ˜¯  |  Snappy |  .snappy |   å¦   |   å’Œæ–‡æœ¬å¤„ç†ä¸€æ ·ï¼Œä¸éœ€è¦å¤„ç†  |

**å‹ç¼©æ€§èƒ½æ¯”è¾ƒ**

|  å‹ç¼©ç®—æ³• | åŸå§‹æ–‡ä»¶å¤§å° | å‹ç¼©æ–‡ä»¶å¤§å° |   å‹ç¼©é€Ÿåº¦   |   è§£å‹é€Ÿåº¦   |
| :---: | :----: | :----: | :------: | :------: |
|  gzip |  8.3GB |  1.8GB | 17.5MB/s |  58MB/s  |
| bzip2 |  8.3GB |  1.1GB |  2.4MB/s |  9.5MB/s |
|  LZO  |  8.3GB |  2.9GB | 49.3MB/s | 74.6MB/s |

**ç”Ÿäº§æ¢ç¯å¢ƒæ€ä¹ˆç”¨**

![image-20230215145738978](Hadoop.assets/image-20230215145738978.png)

**é…ç½®æ–¹å¼**

æŸäº›å‹ç¼©ç®—æ³•éœ€è¦æœ¬åœ°è¿æ¥åº“ï¼Œåœ¨ä½¿ç”¨ç®—æ³•ä¹‹å‰å¯ä»¥é€šè¿‡ `hadoop ckecknative` å‘½ä»¤æŸ¥çœ‹æ”¯æŒå“ªäº›å‹ç¼©æ–¹å¼

```shell
# hadoop ckecknative
Native library checking:
hadoop:  true /home/zh/bin/hadoop-3.1.3/lib/native/libhadoop.so.1.0.0
zlib:    true /lib64/libz.so.1
zstd  :  true /usr/lib64/libzstd.so.1
snappy:  true /usr/lib64/libsnappy.so.1
lz4:     true revision:10301
bzip2:   true /usr/lib64/libbz2.so.1
openssl: false Cannot load libcrypto.so (libcrypto.so: æ— æ³•æ‰“å¼€å…±äº«å¯¹è±¡æ–‡ä»¶: æ²¡æœ‰é‚£ä¸ªæ–‡ä»¶æˆ–ç›®å½•)!
ISA-L:   false libhadoop was built without ISA-L support
```

**æ³¨æ„**ï¼šsnappy éœ€è¦ linux ç¯å¢ƒå’Œ hadoop3.x çš„æ”¯æŒ

|                              å‚æ•°                              |                     é»˜è®¤å€¼                     |     é˜¶æ®µ     |               å»ºè®®              |
| :----------------------------------------------------------: | :-----------------------------------------: | :--------: | :---------------------------: |
|             io.compression.codecxï¼ˆcore-site.xmlï¼‰             |                      æ—                       |     å‹ç¼©     |   Hadoop ä½¿ç”¨æ–‡ä»¶æ‰©å±•ååˆ¤æ–­æ˜¯å¦æ”¯æŒæŸç§ç¼–è§£ç å™¨  |
|        mapreduce.map.output. compressï¼ˆmapred-site.xmlï¼‰       |                    false                    |  mapper è¾“å‡º |        è¿™ä¸ªå‚æ•°è®¾ç½® true å¯ç”¨å‹ç¼©       |
|     mapreduce.map.output. compress.codecï¼ˆmapred-site.xmlï¼‰    | org.apache.hadoop. io.compress.DefaultCodec |  mapperè¾“å‡º  | ä¼ä¸šä½¿ç”¨ LZO æˆ– Snappyç¼–è§£ç å™¨åœ¨æ¬¡é˜¶æ®µå‹ç¼©æ•°æ® |
| mapreduce.output. fileoutputformat.compressï¼ˆmapred-site.xmlï¼‰ |                    false                    | reducer è¾“å‡º |        è¿™ä¸ªå‚æ•°è®¾ä¸º true å¯ç”¨å‹ç¼©       |
| mapreduce.output. fileoutputformat.compressï¼ˆmapred-site.xmlï¼‰ | org.apache.hadoop.io. compress.DefaultCodec | reudcer è¾“å‡º |  ä½¿ç”¨æ ‡å‡†å·¥å…·æˆ–è€…ç¼–è§£ç å™¨ï¼Œå¦‚ gzip å’Œ bzip2  |

åœ¨ä»£ç ä¸­å¯ç”¨éå¸¸çš„ç®€å•ï¼Œåªéœ€è¦åœ¨é©±åŠ¨ç±»ä¸­æ·»åŠ å¦‚ä¸‹é…ç½®å³å¯ï¼š

```java
// è®¾ç½® map é˜¶æ®µçš„å‹ç¼©
configuration.setBoolean("mapreduce.map.output.compress", true);
configuration.setClass("mapreduce.map.output.compress.codec", BZip2Codec.class, CompressionCodec.class);

// è®¾ç½® reduce é˜¶æ®µçš„å‹ç¼©
FileOutputFormat.setCompressOutput(job, true);
FileOutputFormat.setOutputCompressorClass(job, BZip2Codec.class);
```

### YARN

#### ç†è®º

Yarn æ˜¯ä¸€ä¸ªèµ„æºè°ƒåº¦å¹³å°ï¼Œè´Ÿè´£ä¸ºè¿ç®—ç¨‹åºæä¾›æœåŠ¡å™¨è¿ç®—èµ„æºï¼Œç›¸å½“äºä¸€ä¸ªåˆ†å¸ƒå¼çš„æ“ä½œç³»ç»Ÿå¹³å°ï¼Œè€Œ MapReduce ç­‰è¿ç®—ç¨‹åºåˆ™ç›¸å½“äºæ“ä½œç³»ç»Ÿä¹‹ä¸Šçš„åº”ç”¨ç¨‹åºã€‚

**Yarn åŸºç¡€æ¶æ„**

![image-20230225174535608](Hadoop.assets/image-20230225174535608.png)

**Yarn çš„å·¥ä½œæœºåˆ¶**

![image-20230225175135181](Hadoop.assets/image-20230225175135181.png)

å·¥ä½œæµç¨‹å¦‚ä¸‹ï¼š

1.  Mr ç¨‹åºå°†ä»»åŠ¡æäº¤åˆ°å®¢æˆ·ç«¯æ‰€åœ¨çš„èŠ‚ç‚¹
2.  å®¢æˆ·ç«¯å°†å‘ ResourceManager ç”³è¯·ä¸€ä¸ªæ–°çš„ Application
3.  ReourceManager è¿”å›èµ„æºæäº¤è·¯å¾„å’Œ application_id
4.  å®¢æˆ·ç«¯å°†ä»»åŠ¡æ‰€éœ€è¦çš„èµ„æºæäº¤åˆ°æŒ‡å®šçš„ç›®å½•
5.  å®¢æˆ·ç«¯å‘ ResourcesManaer ç”³è¯·è¿è¡Œ mrAppMaster
6.  ResourceManager å°†ç”¨æˆ·çš„è¯·æ±‚åˆå§‹åŒ–ä¸ºä¸€ä¸ª Taskï¼Œæ”¾å…¥è°ƒåº¦é˜Ÿåˆ—
7.  NodeManager é¢†å–åˆ° Task
8.  NodeManager åˆ›å»ºç”¨æ¥æ‰§è¡Œä»»åŠ¡çš„ Containerï¼ˆAppMaster å®¹å™¨ï¼‰
9.  å°†ä»»åŠ¡æ‰€éœ€è¦çš„èµ„æºä¸‹è½½åˆ°æœ¬åœ°
10.  å‘ ReousourceManager ç”³è¯·è¿è¡Œ MapTask ä»»åŠ¡çš„ Container
11.  ä¸åŒçš„ NodeManager é¢†å–åˆ°ä»»åŠ¡ä¹‹åå°†åˆ›å»ºè¿è¡Œ MapTask ä»»åŠ¡çš„ Container
12.  AppMaster å‘ MapTask å‘é€å‘½ä»¤å¯åŠ¨çš„è„šæœ¬
13.  ç­‰å¾… MapTask è¿è¡Œç»“æŸï¼ŒAppMaster å‘ ReousourceManager ç”³è¯· ReduceTask çš„ Container
14.  ReduceTask è¿è¡Œä»»åŠ¡ï¼Œç»“æŸåå‘ AppMaster æ±‡æŠ¥
15.  AppMaster å‘ ReourceManager æ³¨é”€è‡ªå·±

**Mapreduce/HDFS/Yarn**

**è°ƒåº¦å™¨å’Œè°ƒåº¦ç®—æ³•**

ç›®å‰ï¼ŒHadoop ä½œä¸šè°ƒåº¦å™¨ä¸»è¦ç”±ä¸‰ç§ï¼šFIFOã€å®¹é‡ï¼ˆCapacity Schedulerï¼‰è°ƒåº¦å™¨å’Œå…¬å¹³ï¼ˆFair Schedulerï¼‰è°ƒåº¦å™¨ã€‚Apache Hadoop3.1.3 é»˜è®¤çš„èµ„æºè°ƒåº¦å™¨æ˜¯ Capacity Schedulerã€‚

CDH æ¡†æ¶é»˜è®¤è°ƒåº¦å™¨æ˜¯ Fair Schedulerã€‚

å…·ä½“é…ç½®è¯¦è§ï¼š`yarn-defalut.xml` æ–‡ä»¶

```xml
<property>
	<description> </description>
    <name>yarn.resourcemanager.scheduler.class</name
        <value>org.apach.hadoop.server.resourcemanager.scheduler.capacity.CapacityScheduler</value>
</property>
```

**FIFO**

FIFO è°ƒåº¦å™¨ï¼ˆFirst In First Outï¼‰ï¼šå•é˜Ÿåˆ—ï¼Œæ ¹æ®æäº¤ä½œä¸šçš„å…ˆåé¡ºåºï¼Œå…ˆæ¥å…ˆæœåŠ¡ã€‚ä¸€èˆ¬æƒ…å†µä¸‹ä¸æ˜¯ä½¿ç”¨è¯¥è°ƒåº¦å™¨ã€‚

![image-20230225180712308](Hadoop.assets/image-20230225180712308.png)

**å®¹é‡è°ƒåº¦å™¨**

æ˜¯ç”±é›…è™å¼€å‘çš„ã€‚

![image-20230225191153388](Hadoop.assets/image-20230225191153388.png)

![image-20230225191447471](Hadoop.assets/image-20230225191447471.png)

**å…¬å¹³è°ƒåº¦å™¨**

ç”± FaceBook å¼€å‘ã€‚

![image-20230225192019141](Hadoop.assets/image-20230225192019141.png)

![image-20230225193554134](Hadoop.assets/image-20230225193554134.png)

![image-20230225193715879](Hadoop.assets/image-20230225193715879.png)

![image-20230225194228849](Hadoop.assets/image-20230225194228849.png)

![image-20230225194405806](Hadoop.assets/image-20230225194405806.png)

**Yarn åœ¨ç”Ÿäº§ç¯å¢ƒä¸‹éœ€è¦é…ç½®çš„å‚æ•°**

**å‘½ä»¤è¡Œæ“ä½œ Yarn**

#### æ€ä¹ˆç©

**ç”Ÿäº§ç¯å¢ƒä¸‹æ€ä¹ˆé…ç½®**

**å®¹é‡è°ƒåº¦å™¨åœ¨ç”Ÿäº§ç¯å¢ƒæ€ä¹ˆé…ç½®**

**å…¬å¹³è°ƒåº¦å™¨çš„é…ç½®**

**Yarn tool æ¥å£**
